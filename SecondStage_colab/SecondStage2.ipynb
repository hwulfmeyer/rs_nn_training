{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondStage2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJlG_lwKEaQv",
        "colab_type": "text"
      },
      "source": [
        "to do:\n",
        "- image in tensorboard (test alpha mobilenet)\n",
        "- imports aufräumen\n",
        "- Secondstage.py\n",
        "- Konfiguration außerhalb:\n",
        "    - Name output\n",
        "    - cat/ bin/ reg\n",
        "- endliche Anzahl an Runden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHIKxNY3oahf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VO6zc_v7lJ-",
        "colab_type": "text"
      },
      "source": [
        "von Tobi geklaut\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_HjEoWRonVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH4BMdyyorVT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "9e86bc53-bcae-497b-c2af-9feedf5010b7"
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 145674 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85f2szA_pAJg",
        "colab_type": "code",
        "outputId": "3419df9a-42e5-49f2-dac0-f9db8b31d2ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd models/research"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPwg_kkapFJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsskp5qWpJRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJLXPuYIpNg4",
        "colab_type": "code",
        "outputId": "16d21f19-f96c-4707-9685-58284b370898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 904
        }
      },
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.233s\n",
            "\n",
            "OK (skipped=1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "japGTz-bFnCC",
        "colab_type": "code",
        "outputId": "5aaf5099-b71e-4ce4-f726-0f1452064d2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5h9RbyaYC-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/SecondStage_colab/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZWtkiVKShNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/SecondStage_colab/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exoPdhiJ7p1R",
        "colab_type": "text"
      },
      "source": [
        "Second Stage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwRKHys0KBHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NAME =\n",
        "#example: cat_exptype_dataset(training)_dataset(eval)_conf(batch size etc) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqzYclgV64T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_PATH = '/content/gdrive/My Drive/SecondStage_colab/output/'\n",
        "LABEL_MAP_PATH = '/content/gdrive/My Drive/SecondStage_colab/label_map.pbtxt'\n",
        "TRAIN_RECORD = '/content/gdrive/My Drive/data/train/training_rot6.record'\n",
        "EVAL_RECORD = '/content/gdrive/My Drive/data/train/evaluation_rot2.record'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjrsBWe_7sjQ",
        "colab_type": "code",
        "outputId": "425c9868-6a24-4b39-bcc7-274cd26cf4e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/')\n",
        "\n",
        "from SecondStage_colab import second_stage_utils\n",
        "from SecondStage_colab import file_utils"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKaABMtXB-OA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/models/research')\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R7pUpyVcHIf",
        "colab_type": "text"
      },
      "source": [
        "configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1i_AkgfcGUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GPU = True\n",
        "BATCH_SIZE = 1012\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Hbp0ghcZtB",
        "colab_type": "text"
      },
      "source": [
        "label map\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk0ZiaTCthBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/SecondStage_colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOwjdrteceEe",
        "colab_type": "code",
        "outputId": "6f9157c9-d7cd-478c-8790-7177ee3a34c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile label_map.pbtxt\n",
        "\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'bright_blue'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'bright_red'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 3\n",
        "  name: 'bright_green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 4\n",
        "  name: 'dark_blue'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 5\n",
        "  name: 'dark_green' \n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 6\n",
        "  name: 'dark_red'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 7\n",
        "  name: 'bright_white'\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting label_map.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5-N8oYNQ_8C",
        "colab_type": "text"
      },
      "source": [
        "experiment definitioin\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmm4SaY3QXt3",
        "colab_type": "code",
        "outputId": "2b730020-bc03-43ee-e26a-78640863daac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile exp_def.py\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "default_sstage_conf = {\n",
        "    'dataset': 'default',\n",
        "    'types': ['copter','sphero','youbot'],\n",
        "    # converged after 15 / 10 / 5 epochs\n",
        "    # 10 epochs after convergance for evaluation phase\n",
        "    'epochs_cat': 120,\n",
        "    #'epochs_reg': 20,\n",
        "    'epochs_reg': 600,\n",
        "    'epochs_bin': 200,\n",
        "    'optimizer': 'adam',\n",
        "    'learning_rate': 3e-4,\n",
        "    'dropout': 0.2,\n",
        "    'alpha': 0.5,\n",
        "    'img_size': 35,\n",
        "    'separate_cat_ori': True,\n",
        "    'cat_weight': 1.0,\n",
        "    'reg_weight': 1.0,\n",
        "    'bin_weight': 1.0,\n",
        "    'enable_reg': False,\n",
        "    'enable_bin': True,\n",
        "    'repetions': 4,\n",
        "}\n",
        "\n",
        "def create_all_sstage_experiments():\n",
        "    configs = []\n",
        "    configs.extend(create_sstage_default())\n",
        "    configs.extend(bin_mod())\n",
        "    return configs\n",
        "\n",
        "def create_sstage_default():\n",
        "    config = []\n",
        "    modified = deepcopy(default_sstage_conf)\n",
        "    modified['name'] = \"sstage_default\"\n",
        "    modified['enable_reg'] = True\n",
        "    config.append(deepcopy(modified))\n",
        "    return config\n",
        "\n",
        "def bin_mod():\n",
        "    config = []\n",
        "    modified = deepcopy(default_sstage_conf)\n",
        "    modified['name'] = \"bin_mod\"\n",
        "    modified['enable_reg'] = True\n",
        "    config.append(deepcopy(modified))\n",
        "    return config"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting exp_def.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDJatt09QfGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import re\n",
        "from datetime import datetime\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from keras import applications\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Reshape, Conv2D, Activation\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, Callback\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "import csv, json, pickle\n",
        "from lxml import etree\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG9YYdriX8WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_record, conf, types, out, rep=1):\n",
        "\n",
        "    from file_utils import save_json\n",
        "    from second_stage_utils import tf_record_load_crops, tf_record_extract_crops, data_to_keras, angle_to_bin, angle_mse, angle_mae, angle_bin_error, TensorBoardCustom\n",
        "\n",
        "    timestamp = \"{:%Y-%m-%d-%H-%M}\".format(datetime.now())\n",
        "    log_path = LOG_PATH + conf['name'] + '_' + \\\n",
        "                ''.join(types) + out + '/' + \\\n",
        "                timestamp + '-r' + str(rep) + '/'\n",
        "    os.makedirs(log_path, exist_ok=True)\n",
        "    save_json(log_path + '/experiment_config.json', conf)\n",
        "\n",
        "    label_map = label_map_util.create_category_index_from_labelmap(LABEL_MAP_PATH)\n",
        "    #label_map = create_category_index_from_labelmap(LABEL_MAP_PATH)\n",
        "\n",
        "    num_classes = label_map_util.get_max_label_map_index(\n",
        "                           label_map_util.load_labelmap(LABEL_MAP_PATH)) #+ 1\n",
        "    print(\"x\")\n",
        "    X,Y,Z,_ = tf_record_load_crops([train_record])\n",
        "    \n",
        "    X_train, Y_train, Z_train = data_to_keras(X,Y,Z,num_classes,conf['img_size'])\n",
        "    Z2_train = angle_to_bin(Z_train)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "    print(Y_train.shape)\n",
        "    print(num_classes)\n",
        "    print(Z2_train.shape)\n",
        "    print(NUM_ORI_BINS)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "\n",
        "    eval_records = EVAL_RECORD\n",
        "\n",
        "    X,Y,Z,_ = tf_record_extract_crops([eval_records], 1, 0.0, 0.0)\n",
        "    X_val, Y_val, Z_val = data_to_keras(X,Y,Z,num_classes,conf['img_size'])\n",
        "    Z2_val = angle_to_bin(Z_val)\n",
        "\n",
        "    assert len(X_val) > 0 and len(Y_val) > 0 and len(Z_val) > 0, \\\n",
        "        '{} is incomplete'.format(eval_records)\n",
        "    mobilenet_base = applications.mobilenet.MobileNet(alpha = conf['alpha'],\n",
        "                                                      weights = \"imagenet\",\n",
        "                                                      include_top=False,\n",
        "                                                      input_shape = (\n",
        "                                                      conf['img_size'],\n",
        "                                                      conf['img_size'],\n",
        "                                                        3\n",
        "                                                      ))\n",
        "    shape = (1, 1, int(1024 * conf['alpha']))\n",
        "    x = GlobalAveragePooling2D()(mobilenet_base.output)\n",
        "    x = Reshape(shape, name='reshape_1')(x)\n",
        "    x = Dropout(conf['dropout'], name='dropout')(x)\n",
        "    # Branch regression\n",
        "    reg = Conv2D(1, (1, 1),\n",
        "               padding='same', name='conv_reg')(x)\n",
        "    reg = Activation('linear', name='act_linear')(reg)\n",
        "    reg = Reshape((1,), name='reg_out')(reg)\n",
        "    # Branch orientation classification with bins\n",
        "    bin = Conv2D(NUM_ORI_BINS, (1, 1),\n",
        "               padding='same', name='conv_bin')(x)\n",
        "    bin = Activation('softmax', name='act_bin')(bin)\n",
        "    bin = Reshape((NUM_ORI_BINS,), name='bin_out')(bin)\n",
        "    # Branch classification\n",
        "    cat = Conv2D(num_classes, (1, 1),\n",
        "               padding='same', name='conv_cat')(x)\n",
        "    cat = Activation('softmax', name='act_softmax')(cat)\n",
        "    cat = Reshape((num_classes,), name='cat_out')(cat)\n",
        "\n",
        "    # creating the final model\n",
        "    model_final = None\n",
        "    model_final = Model(inputs = mobilenet_base.input, outputs = [cat,reg,bin])\n",
        "\n",
        "    if conf['optimizer'] == 'rmsprop':\n",
        "        optimizer = optimizers.RMSprop(lr=conf['learning_rate'])\n",
        "    elif conf['optimizer'] == 'adam':\n",
        "        optimizer = optimizers.Adam(lr=conf['learning_rate'])\n",
        "    else:\n",
        "        raise Error('Unknown optimizer: ' + conf['optimizer'])\n",
        "\n",
        "    model_final.compile(optimizer = optimizer,\n",
        "                        loss={'cat_out': 'categorical_crossentropy',\n",
        "                              'reg_out': angle_mse,\n",
        "                              'bin_out': 'categorical_crossentropy',\n",
        "                              #'bin_out': 'binary_crossentropy'\n",
        "                        },\n",
        "                        loss_weights={'cat_out': conf['cat_weight'],\n",
        "                                      'reg_out': conf['reg_weight'],\n",
        "                                      'bin_out': conf['bin_weight']},\n",
        "                        metrics ={'cat_out': 'accuracy',\n",
        "                                  'reg_out': angle_mae,\n",
        "                                  'bin_out': angle_bin_error})\n",
        "\n",
        "    summary = TensorBoardCustom(log_dir=log_path,label_map=label_map)\n",
        "    filepath=log_path+\"model-{epoch:02d}.h5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, verbose=1, period=20)\n",
        "\n",
        "    \"\"\"callbacks=[summary,checkpoint],\"\"\"\n",
        "\n",
        "    model_final.fit(\n",
        "        X_train,\n",
        "        {'cat_out': Y_train, 'reg_out': Z_train, 'bin_out': Z2_train},\n",
        "        validation_data=(X_val,[Y_val,Z_val, Z2_val]),\n",
        "        batch_size=BATCH_SIZE, epochs=conf['epochs'], verbose=0,\n",
        "        callbacks=[summary,checkpoint],\n",
        "        shuffle=True\n",
        "    )\n",
        "    model_final.save(log_path+\"model-final.h5\")\n",
        "    print(\"Finished training for {}_{}\".format(conf['name'],t))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjhzN9oBxzHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from SecondStage_colab import exp_def\n",
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jru6gJiHAVl",
        "colab_type": "code",
        "outputId": "47a67846-943c-42d7-84f3-599b14ae5da3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "ANGLES_PER_BIN = 1\n",
        "NUM_ORI_BINS = 360\n",
        "\n",
        "exp = exp_def.create_all_sstage_experiments()\n",
        "print(BATCH_SIZE)\n",
        "for or_conf in tqdm(exp):\n",
        "    print(\"or_conf\", or_conf)\n",
        "    for r in range(or_conf['repetions']): \n",
        "        #train_records = get_recursive_file_list(TRAIN_DIR,file_matchers=[or_conf['dataset']])\n",
        "        train_records = [TRAIN_RECORD]\n",
        "        for t in or_conf['types']:\n",
        "            for out in ['_cat','_reg','_bin','']:\n",
        "                conf = deepcopy(or_conf)\n",
        "                train_instance_name = conf['name']+'_'+t+out\n",
        "                if not conf['separate_cat_ori'] and out != '':\n",
        "                    continue\n",
        "                if conf['separate_cat_ori']:\n",
        "                    if out == '':\n",
        "                        continue\n",
        "                    elif out == '_cat':\n",
        "                        conf['reg_weight'] = 0.0\n",
        "                        conf['bin_weight'] = 0.0\n",
        "                        conf['epochs'] = conf['epochs_cat']\n",
        "                    elif out == '_reg' and conf['enable_reg']:\n",
        "                        conf['cat_weight'] = 0.0\n",
        "                        conf['bin_weight'] = 0.0\n",
        "                        conf['epochs'] = conf['epochs_reg']\n",
        "                    elif out == '_bin' and conf['enable_bin']:\n",
        "                        conf['cat_weight'] = 0.0\n",
        "                        conf['reg_weight'] = 0.0\n",
        "                        conf['epochs'] = conf['epochs_bin']\n",
        "                    else:\n",
        "                        print('UNKNOWN OUTPUT CONFIG {}'.format(out))\n",
        "                        continue\n",
        "                if not re.match('bin_mod_sphero_bin', train_instance_name): \n",
        "                    print('Skip '+train_instance_name)\n",
        "                    continue            \n",
        "                #record_for_type = [e for e in train_records if t in e]\n",
        "                #print(\"record_for_type: \", len(record_for_type))\n",
        "                #assert len(record_for_type) == 1, \\\n",
        "                #       \"{} for {} has not one item\".format(record_for_type, train_instance_name)\n",
        "                print(\"Start training\")\n",
        "                \n",
        "                if not GPU:\n",
        "                    p = Process(\n",
        "                      target=train,\n",
        "                      args=(train_records[0], conf, ['sphero'], out, r)\n",
        "                    )\n",
        "                    p.start() \n",
        "                else:\n",
        "                 \n",
        "                  train(train_records[0], conf, ['sphero'], out)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1012\n",
            "or_conf {'dataset': 'default', 'types': ['copter', 'sphero', 'youbot'], 'epochs_cat': 120, 'epochs_reg': 600, 'epochs_bin': 200, 'optimizer': 'adam', 'learning_rate': 0.0003, 'dropout': 0.2, 'alpha': 0.5, 'img_size': 35, 'separate_cat_ori': True, 'cat_weight': 1.0, 'reg_weight': 1.0, 'bin_weight': 1.0, 'enable_reg': True, 'enable_bin': True, 'repetions': 4, 'name': 'sstage_default'}\n",
            "Skip sstage_default_copter_cat\n",
            "Skip sstage_default_copter_reg\n",
            "Skip sstage_default_copter_bin\n",
            "Skip sstage_default_sphero_cat\n",
            "Skip sstage_default_sphero_reg\n",
            "Skip sstage_default_sphero_bin\n",
            "Skip sstage_default_youbot_cat\n",
            "Skip sstage_default_youbot_reg\n",
            "Skip sstage_default_youbot_bin\n",
            "Skip sstage_default_copter_cat\n",
            "Skip sstage_default_copter_reg\n",
            "Skip sstage_default_copter_bin\n",
            "Skip sstage_default_sphero_cat\n",
            "Skip sstage_default_sphero_reg\n",
            "Skip sstage_default_sphero_bin\n",
            "Skip sstage_default_youbot_cat\n",
            "Skip sstage_default_youbot_reg\n",
            "Skip sstage_default_youbot_bin\n",
            "Skip sstage_default_copter_cat\n",
            "Skip sstage_default_copter_reg\n",
            "Skip sstage_default_copter_bin\n",
            "Skip sstage_default_sphero_cat\n",
            "Skip sstage_default_sphero_reg\n",
            "Skip sstage_default_sphero_bin\n",
            "Skip sstage_default_youbot_cat\n",
            "Skip sstage_default_youbot_reg\n",
            "Skip sstage_default_youbot_bin\n",
            "Skip sstage_default_copter_cat\n",
            "Skip sstage_default_copter_reg\n",
            "Skip sstage_default_copter_bin\n",
            "Skip sstage_default_sphero_cat\n",
            "Skip sstage_default_sphero_reg\n",
            "Skip sstage_default_sphero_bin\n",
            "Skip sstage_default_youbot_cat\n",
            "Skip sstage_default_youbot_reg\n",
            "Skip sstage_default_youbot_bin\n",
            "or_conf {'dataset': 'default', 'types': ['copter', 'sphero', 'youbot'], 'epochs_cat': 120, 'epochs_reg': 600, 'epochs_bin': 200, 'optimizer': 'adam', 'learning_rate': 0.0003, 'dropout': 0.2, 'alpha': 0.5, 'img_size': 35, 'separate_cat_ori': True, 'cat_weight': 1.0, 'reg_weight': 1.0, 'bin_weight': 1.0, 'enable_reg': True, 'enable_bin': True, 'repetions': 4, 'name': 'bin_mod'}\n",
            "Skip bin_mod_copter_cat\n",
            "Skip bin_mod_copter_reg\n",
            "Skip bin_mod_copter_bin\n",
            "Skip bin_mod_sphero_cat\n",
            "Skip bin_mod_sphero_reg\n",
            "Start training\n",
            "x\n",
            "Loaded 64800 crops from ['/content/gdrive/My Drive/data/train/training_rot6.record']\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n",
            "(64800, 7)\n",
            "7\n",
            "(64800, 360)\n",
            "360\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_5_0_224_tf_no_top.h5\n",
            "5578752/5577668 [==============================] - 1s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/SecondStage_colab/second_stage_utils.py:22: The name tf.mod is deprecated. Please use tf.math.mod instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/SecondStage_colab/second_stage_utils.py:181: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/SecondStage_colab/second_stage_utils.py:182: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/SecondStage_colab/second_stage_utils.py:187: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/SecondStage_colab/output/bin_mod_sphero_bin/2020-01-17-13-19-r1/model-20.h5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-e7e8bc543df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_records\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sphero'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-23-c34b841b602d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_record, conf, types, out, rep)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     )\n\u001b[1;32m    101\u001b[0m     \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"model-final.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
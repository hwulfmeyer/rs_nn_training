{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, datetime\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from threading import Thread\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CKPT = '/media/data/LocalizationData/TFObjectDetection/inference/first_stage_ssd_mobilenet2.pb/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = \"/media/data/LocalizationData/TFObjectDetection/data/copter_label_map.pbtxt\"\n",
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = '/media/data/LocalizationData/Validation'\n",
    "TEST_IMAGE_PATHS = []\n",
    "for root, dirs, files in os.walk(PATH_TO_TEST_IMAGES_DIR):\n",
    "    for f in files:\n",
    "        if f.endswith(\".jpg\"):\n",
    "            TEST_IMAGE_PATHS.append(root+'/'+f)\n",
    "TEST_IMAGE_PATHS.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dict():\n",
    "    # Get handles to input and output tensors\n",
    "    ops = tf.get_default_graph().get_operations()\n",
    "    all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "    tensor_dict = {}\n",
    "    for key in [\n",
    "            'num_detections', 'detection_boxes', 'detection_scores',\n",
    "            'detection_classes', 'detection_masks'\n",
    "    ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "            tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                    tensor_name)\n",
    "    return tensor_dict\n",
    "\n",
    "def inference(sess, tensor_dict, image):\n",
    "    image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Run inference\n",
    "    output_dict = sess.run(tensor_dict,\n",
    "       feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    output_dict['detection_classes'] = output_dict[\n",
    "            'detection_classes'][0].astype(np.uint8)\n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "    if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict\n",
    "\n",
    "def save_visualization(image_np, output_dict,i):\n",
    "    # Visualization of the results of a detection.\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np,\n",
    "            output_dict['detection_boxes'],\n",
    "            output_dict['detection_classes'],\n",
    "            output_dict['detection_scores'],\n",
    "            category_index,\n",
    "            instance_masks=output_dict.get('detection_masks'),\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=2)\n",
    "    image_pil = Image.fromarray(np.uint8(image_np)).convert('RGB')\n",
    "    with tf.gfile.Open('/media/data/LocalizationData/Output/Inference/'+TIMESTAMP+'/'+str(i), 'w') as fid:\n",
    "        image_pil.save(fid, 'PNG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "SAVE_RESULTS=False\n",
    "TIMESTAMP = \"{:%Y-%m-%d-%H-%M-%S}\".format(datetime.datetime.now())\n",
    "if SAVE_RESULTS:\n",
    "    os.makedirs('/media/data/LocalizationData/Output/Inference/'+TIMESTAMP, exist_ok=True)\n",
    "i = 0\n",
    "#image = Image.open('/media/data/LocalizationData/Output/Compositor/2018-03-30-14-52-48-imgs/2018-03-30-14-52-48-img0.png').convert('RGB')\n",
    "#image = image.resize((200,150))\n",
    "#image_np = load_image_into_numpy_array(image)\n",
    "#image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "with detection_graph.as_default():\n",
    "    with tf.Session() as sess:\n",
    "        tensor_dict = create_tensor_dict()\n",
    "        for image_path in tqdm(TEST_IMAGE_PATHS):\n",
    "            # It's way faster to resize before TF (about 2.15s vs 3.2s)\n",
    "            image = Image.open(image_path).convert('RGB').resize((200,150))\n",
    "            image_np = load_image_into_numpy_array(image)\n",
    "            image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "            output_dict = inference(sess,tensor_dict,image_np)\n",
    "            \n",
    "            if SAVE_RESULTS:\n",
    "                thread = Thread(\n",
    "                    target=save_visualization,\n",
    "                    args=(image_np, output_dict, i)\n",
    "                )\n",
    "                thread.start()            \n",
    "            i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#Fix problem with ros python path\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/dist-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, datetime\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import math\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "from threading import Thread\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "from keras.applications import mobilenet\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from Utils.utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_CKPT = '/media/data/LocalizationData/TFObjectDetection/inference/first_stage_ssd_mobilenet2.pb/frozen_inference_graph.pb'\n",
    "PATH_TO_LABELS = \"/media/data/LocalizationData/TFObjectDetection/data/copter_label_map.pbtxt\"\n",
    "NUM_CLASSES = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tensor_dict():\n",
    "    # Get handles to input and output tensors\n",
    "    ops = tf.get_default_graph().get_operations()\n",
    "    all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "    tensor_dict = {}\n",
    "    for key in [\n",
    "            'num_detections', 'detection_boxes', 'detection_scores',\n",
    "            'detection_classes', 'detection_masks'\n",
    "    ]:\n",
    "        tensor_name = key + ':0'\n",
    "        if tensor_name in all_tensor_names:\n",
    "            tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                    tensor_name)\n",
    "    return tensor_dict\n",
    "\n",
    "def inference(sess, graph, tensor_dict, image):\n",
    "    image_tensor = graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "    # Run inference\n",
    "    output_dict = sess.run(tensor_dict,\n",
    "       feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "    # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "    output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "    output_dict['detection_classes'] = output_dict[\n",
    "            'detection_classes'][0].astype(np.uint8)\n",
    "    output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "    output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "    if 'detection_masks' in output_dict:\n",
    "        output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_TEST_IMAGES_DIR = '/media/data/LocalizationData/Validation/CoptersFlying5'\n",
    "TEST_IMAGE_PATHS = get_recursive_file_list(PATH_TO_TEST_IMAGES_DIR, file_extensions=\".jpg\")\n",
    "\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "#first_stage_input = []\n",
    "#for image_path in TEST_IMAGE_PATHS:\n",
    "#    image = Image.open(image_path).convert('RGB').resize((200,150))\n",
    "#    image_np = load_image_into_numpy_array(image)\n",
    "#    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "#    first_stage_input.append(image_np_expanded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_stage_model = load_model('/media/data/LocalizationData/TFObjectDetection/inference/SecondStage/Mobilenet.h5',\n",
    "                   custom_objects={\n",
    "                   'relu6': mobilenet.relu6,\n",
    "                   'DepthwiseConv2D': mobilenet.DepthwiseConv2D,\n",
    "                   'custom_mse': custom_mse,\n",
    "                   'custom_mae': custom_mae})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFirstStagePredictions(image, output_dict, min_score_thresh=0.5):\n",
    "    boxes = output_dict['detection_boxes']\n",
    "    classes = output_dict['detection_classes']\n",
    "    scores = output_dict['detection_scores']\n",
    "    extracted_boxes, extracted_classes, extracted_scores = [],[],[]\n",
    "    objects = []\n",
    "    height, width = image.height, image.width\n",
    "    for i in range(boxes.shape[0]):\n",
    "        if scores is None or scores[i] > min_score_thresh:\n",
    "            box = tuple(boxes[i].tolist())\n",
    "            y0=int(box[0]*height)\n",
    "            x0=int(box[1]*width)\n",
    "            y1=int(box[2]*height)\n",
    "            x1=int(box[3]*width)\n",
    "            obj = image.crop((x0, y0, x1, y1))\n",
    "            obj = make_square(obj, 128)\n",
    "            obj = np.asarray(obj)\n",
    "            objects.append(obj)\n",
    "            extracted_boxes.append(boxes[i])\n",
    "            extracted_classes.append(classes[i])\n",
    "            extracted_scores.append(scores[i])\n",
    "    output_dict['detection_boxes'] = np.asarray(extracted_boxes)\n",
    "    output_dict['detection_classes'] = np.asarray(extracted_classes)\n",
    "    output_dict['detection_scores'] = np.asarray(extracted_scores)\n",
    "    return objects, output_dict\n",
    "\n",
    "def visualize_poses(image, boxes, poses, arrow_length = 100, arrow_width = 4):\n",
    "    for i in range(boxes.shape[0]):\n",
    "        box = tuple(boxes[i].tolist())\n",
    "        cy = int((box[0]+box[2])/2 * image.shape[0])\n",
    "        cx = int((box[1]+box[3])/2 * image.shape[1])\n",
    "        theta = poses[i][0]\n",
    "        xOff = math.sin(theta*np.pi/180)*arrow_length\n",
    "        yOff = math.cos(theta*np.pi/180)*arrow_length\n",
    "        cv2.arrowedLine(image,\n",
    "                    (int(cx),int(cy)),\n",
    "                    (int(cx-xOff),int(cy-yOff)), \n",
    "                    (255,0,0),arrow_width)\n",
    "        #draw = ImageDraw.Draw(image) \n",
    "        #draw.line((cx,cy, int(cx-xOff),int(cy-yOff)), fill=128)\n",
    "\n",
    "def save_visualization(image, output_dict,i):\n",
    "    image_np = np.array(image)\n",
    "    #image_np = load_image_into_numpy_array(image)\n",
    "    #vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "    #            image_np,\n",
    "    #            output_dict['detection_boxes'],\n",
    "    #            output_dict['sub_classes'],\n",
    "    #            output_dict['sub_scores'],\n",
    "    #            category_index,\n",
    "    #            use_normalized_coordinates=True,\n",
    "    #            line_thickness=2)\n",
    "    if 'poses' in output_dict:\n",
    "        visualize_poses(image_np, output_dict['detection_boxes'], output_dict['poses'])\n",
    "    image_pil = Image.fromarray(np.uint8(image_np)).convert('RGB')\n",
    "    with tf.gfile.Open('/media/data/LocalizationData/Output/Inference/'+TIMESTAMP+'/'+str(i)+'.jpg', 'w') as fid:\n",
    "        image_pil.save(fid, 'JPEG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "SAVE_RESULTS=True\n",
    "TIMESTAMP = \"{:%Y-%m-%d-%H-%M-%S}\".format(datetime.datetime.now())\n",
    "if SAVE_RESULTS:\n",
    "    os.makedirs('/media/data/LocalizationData/Output/Inference/'+TIMESTAMP, exist_ok=True)\n",
    "i = 0\n",
    "with detection_graph.as_default():\n",
    "    sess = tf.Session()\n",
    "    tensor_dict = create_tensor_dict()\n",
    "# TODO: filter colors of copter\n",
    "for image_path in tqdm(TEST_IMAGE_PATHS):\n",
    "    image_hr = Image.open(image_path).convert('RGB')\n",
    "    image = image_hr.resize((200,150))\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    output_dict = inference(sess,detection_graph,tensor_dict,image_np)\n",
    "\n",
    "    # Speed up: separate thread\n",
    "    objects, output_dict = extractFirstStagePredictions(image_hr, output_dict)\n",
    "    if len(objects) > 0:\n",
    "        prediction = second_stage_model.predict(np.asarray(objects))\n",
    "        output_dict['poses'] = prediction[1]\n",
    "        output_dict['sub_classes'] = np.argmax(prediction[0], axis=1)\n",
    "        output_dict['sub_scores'] = np.max(prediction[0], axis=1)\n",
    "    if SAVE_RESULTS:\n",
    "        thread = Thread(\n",
    "            target=save_visualization,\n",
    "            args=(image_hr, output_dict, i)\n",
    "        )\n",
    "        thread.start()   \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

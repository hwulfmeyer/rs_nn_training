{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondStage2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJlG_lwKEaQv",
        "colab_type": "text"
      },
      "source": [
        "to do:\n",
        "- image in tensorboard (test alpha mobilenet)\n",
        "- imports aufräumen\n",
        "- Secondstage.py\n",
        "- Konfiguration außerhalb:\n",
        "    - Name output\n",
        "    - cat/ bin/ reg\n",
        "- endliche Anzahl an Runden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BcJ4A6G0rjB",
        "colab_type": "code",
        "outputId": "e332afa4-ec37-48bc-8a1b-d7149bb1b520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 955
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'models' already exists and is not an empty directory.\n",
            "/content/models/research\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/inception_resnet_v2.py:374: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/models/research/slim/nets/mobilenet/mobilenet.py:397: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.168s\n",
            "\n",
            "OK (skipped=1)\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5h9RbyaYC-b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f70bd952-8b1c-44f2-d5f6-e696166a242f"
      },
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from datetime import datetime\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from keras import applications, optimizers, backend as K\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Reshape, Conv2D, Activation\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, Callback, LambdaCallback\n",
        "from keras.utils import np_utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import io\n",
        "import sys\n",
        "import csv, json, pickle\n",
        "from lxml import etree\n",
        "\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/')\n",
        "from SecondStage_colab import second_stage_utils\n",
        "from SecondStage_colab import file_utils\n",
        "\n",
        "sys.path.append('/content/gdrive/My Drive/SecondStage_colab/')\n",
        "os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/SecondStage_colab/'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqzYclgV64T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NAME =\n",
        "#example: cat_exptype_dataset(training)_dataset(eval)_conf(batch size etc) \n",
        "\n",
        "LOG_PATH = '/content/gdrive/My Drive/SecondStage_colab/output/'\n",
        "LABEL_MAP_PATH = '/content/gdrive/My Drive/SecondStage_colab/label_map.pbtxt'\n",
        "TRAIN_RECORD = '/content/gdrive/My Drive/data/generated/SecondStage_X/training_rot9_9colors.record'\n",
        "EVAL_RECORD = '/content/gdrive/My Drive/data/generated/SecondStage_X/validation_rot2_9colors.record'\n",
        "\n",
        "GPU = True\n",
        "BATCH_SIZE = 7425"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG9YYdriX8WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from file_utils import save_json\n",
        "from second_stage_utils import *\n",
        "\n",
        "def train(train_record, conf, out, rep=1):\n",
        "    timestamp = \"{:%Y-%m-%d-%H-%M}\".format(datetime.now())\n",
        "    log_path = LOG_PATH + conf['name'] + '_' + out + '/' + timestamp + '-r' + str(rep) + '/'\n",
        "    os.makedirs(log_path, exist_ok=True)\n",
        "    save_json(log_path + '/experiment_config.json', conf)\n",
        "\n",
        "    label_map = label_map_util.create_category_index_from_labelmap(LABEL_MAP_PATH)\n",
        "\n",
        "    num_classes = label_map_util.get_max_label_map_index(label_map_util.load_labelmap(LABEL_MAP_PATH)) + 1\n",
        "\n",
        "    X,Y,Z,_ = tf_record_load_crops([train_record])\n",
        "\n",
        "    X_train, Y_train, Z_train = data_to_keras(X,Y,Z,num_classes,conf['img_size'])\n",
        "    Z2_train = angle_to_bin(Z_train)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "    print(Y_train.shape)\n",
        "    print(num_classes)\n",
        "    print(Z2_train.shape)\n",
        "    print(NUM_ORI_BINS)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "\n",
        "    eval_records = EVAL_RECORD\n",
        "\n",
        "    X,Y,Z,_ = tf_record_extract_crops([eval_records], 1, 0.0, 0.0)\n",
        "    X_val, Y_val, Z_val = data_to_keras(X,Y,Z,num_classes,conf['img_size'])\n",
        "    Z2_val = angle_to_bin(Z_val)\n",
        "\n",
        "    assert len(X_val) > 0 and len(Y_val) > 0 and len(Z_val) > 0, '{} is incomplete'.format(eval_records)\n",
        "\n",
        "    outputs = None\n",
        "    model_final = None\n",
        "    summary = TensorBoardCustom(log_dir=log_path, label_map=label_map, AddCustomMetrics=(out == '_cat'))\n",
        "\n",
        "    filepath=log_path+\"model-{epoch:02d}.h5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, verbose=1, period=20)\n",
        "    if conf['optimizer'] == 'rmsprop':\n",
        "        optimizer = optimizers.RMSprop(lr=conf['learning_rate'])\n",
        "    elif conf['optimizer'] == 'adam':\n",
        "        optimizer = optimizers.Adam(lr=conf['learning_rate'])\n",
        "    else:\n",
        "        raise Error('Unknown optimizer: ' + conf['optimizer'])\n",
        "\n",
        "\n",
        "    mobilenet_base = applications.mobilenet.MobileNet(alpha = conf['alpha'],\n",
        "                                                      weights = \"imagenet\",\n",
        "                                                      include_top=False,\n",
        "                                                      input_shape = (\n",
        "                                                      conf['img_size'],\n",
        "                                                      conf['img_size'],\n",
        "                                                        3\n",
        "                                                      ))\n",
        "    shape = (1, 1, int(1024 * conf['alpha']))\n",
        "    x = GlobalAveragePooling2D()(mobilenet_base.output)\n",
        "    x = Reshape(shape, name='reshape_1')(x)\n",
        "    x = Dropout(conf['dropout'], name='dropout')(x)\n",
        "\n",
        "    if out == '_cat':\n",
        "      # Branch classification\n",
        "      cat = Conv2D(num_classes, (1, 1),\n",
        "                padding='same', name='conv_cat')(x)\n",
        "      cat = Activation('softmax', name='act_softmax')(cat)\n",
        "      cat = Reshape((num_classes,), name='cat_out')(cat)\n",
        "      outputs = cat\n",
        "      model_final = Model(inputs = mobilenet_base.input, outputs = outputs)\n",
        "      model_final.compile(optimizer = optimizer,\n",
        "                          loss={'cat_out': 'categorical_crossentropy'},\n",
        "                          metrics ={'cat_out': 'accuracy'})\n",
        "      model_final.fit(\n",
        "        X_train,\n",
        "        {'cat_out': Y_train},\n",
        "        validation_data=(X_val, Y_val),\n",
        "        batch_size=BATCH_SIZE, epochs = conf['epochs_cat'], verbose=1,\n",
        "        callbacks=[summary,checkpoint],\n",
        "        shuffle=True\n",
        "      )\n",
        "      \n",
        "    elif out == '_reg':\n",
        "      # Branch regression\n",
        "      reg = Conv2D(1, (1, 1),\n",
        "                padding='same', name='conv_reg')(x)\n",
        "      reg = Activation('linear', name='act_linear')(reg)\n",
        "      reg = Reshape((1,), name='reg_out')(reg)\n",
        "      outputs = reg\n",
        "      model_final = Model(inputs = mobilenet_base.input, outputs = outputs)\n",
        "      model_final.compile(optimizer = optimizer,\n",
        "                          loss={'reg_out': angle_mse},\n",
        "                          metrics ={'reg_out': angle_mae})\n",
        "      model_final.fit(\n",
        "        X_train,\n",
        "        {'reg_out': Z_train},\n",
        "        validation_data=(X_val, Z_val),\n",
        "        batch_size=BATCH_SIZE, epochs = conf['epochs_reg'], verbose=1,\n",
        "        callbacks=[summary,checkpoint],\n",
        "        shuffle=True\n",
        "      )\n",
        "            \n",
        "    elif out == '_bin':\n",
        "      # Branch orientation classification with bins\n",
        "      bin = Conv2D(NUM_ORI_BINS, (1, 1),\n",
        "                padding='same', name='conv_bin')(x)\n",
        "      bin = Activation('softmax', name='act_bin')(bin)\n",
        "      bin = Reshape((NUM_ORI_BINS,), name='bin_out')(bin)\n",
        "      outputs = bin\n",
        "      model_final = Model(inputs = mobilenet_base.input, outputs = outputs)\n",
        "      model_final.compile(optimizer = optimizer,\n",
        "                          loss= {'bin_out': 'categorical_crossentropy'},\n",
        "                          metrics = [angle_bin_mae, angle_bin_rmse])\n",
        "      model_final.fit(\n",
        "        X_train,\n",
        "        {'bin_out': Z2_train},\n",
        "        validation_data=(X_val, Z2_val),\n",
        "        batch_size=BATCH_SIZE, epochs = conf['epochs_bin'], verbose=1,\n",
        "        callbacks=[summary,checkpoint],\n",
        "        shuffle=True\n",
        "      )\n",
        "    else:\n",
        "        print('UNKNOWN OUTPUT CONFIG {}'.format(out))\n",
        "\n",
        "    model_final.save(log_path+\"model-final.h5\")\n",
        "    print(log_path)\n",
        "    print(\"Finished training for {}\".format(conf['name']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jru6gJiHAVl",
        "colab_type": "code",
        "outputId": "08043536-d61b-438f-f206-acac15697920",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        }
      },
      "source": [
        "default_sstage_conf = {\n",
        "    'dataset': 'default',\n",
        "    'epochs_cat': 40,\n",
        "    'epochs_reg': 40,\n",
        "    'epochs_bin': 40,\n",
        "    'optimizer': 'adam',\n",
        "    'learning_rate': 3e-4,\n",
        "    'dropout': 0,\n",
        "    'alpha': 0.5,\n",
        "    'img_size': 35,\n",
        "    'repetions': 1,\n",
        "}\n",
        "\n",
        "def create_all_sstage_experiments():\n",
        "    configs = []\n",
        "    configs.extend(create_sstage_default())\n",
        "    return configs\n",
        "\n",
        "def create_sstage_default():\n",
        "    config = []\n",
        "    modified = deepcopy(default_sstage_conf)\n",
        "    modified['name'] = \"sstage_default\"\n",
        "    config.append(deepcopy(modified))\n",
        "    return config\n",
        "\n",
        "exp = create_all_sstage_experiments()\n",
        "TORUN = []\n",
        "TORUN.append('_bin')\n",
        "#TORUN.append('_cat')\n",
        "\n",
        "print(BATCH_SIZE)\n",
        "for config in tqdm(exp):\n",
        "    print(\"or_conf\", config)\n",
        "    for r in range(config['repetions']):\n",
        "        train_records = [TRAIN_RECORD]\n",
        "        for out in TORUN: # \n",
        "            conf = deepcopy(config)\n",
        "            train_instance_name = conf['name']+'_'+out\n",
        "            print(\"Start training\")\n",
        "            \n",
        "            if not GPU:\n",
        "                p = Process(\n",
        "                  target=train,\n",
        "                  args=(train_records[0], conf, out, r)\n",
        "                )\n",
        "                p.start() \n",
        "            else:\n",
        "              train(train_records[0], conf, out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "7425\n",
            "or_conf {'dataset': 'default', 'epochs_cat': 40, 'epochs_reg': 40, 'epochs_bin': 40, 'optimizer': 'adam', 'learning_rate': 0.0003, 'dropout': 0, 'alpha': 0.5, 'img_size': 35, 'repetions': 1, 'name': 'sstage_default'}\n",
            "Start training\n",
            "Loaded 145800 crops from ['/content/gdrive/My Drive/data/generated/SecondStage_X/training_rot9_9colors.record']\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n",
            "(145800, 10)\n",
            "10\n",
            "(145800, 360)\n",
            "360\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nukOQRHZg0uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "# LOG_PATH did not work for some reason\n",
        "%tensorboard --logdir '/content/gdrive/My Drive/SecondStage_colab/output/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwb-Lucxg2Bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorboard >piplog 2>&1\n",
        "!tensorboard dev upload --logdir '/content/gdrive/My Drive/SecondStage_colab/output/'\n",
        "#!tensorboard dev list\n",
        "# You must replace YOUR_EXPERIMENT_ID with the value output from the previous\n",
        "# tensorboard `list` command or `upload` command.  For example\n",
        "# `tensorboard dev delete --experiment_id pQpJNh00RG2Lf1zOe9BrQA`\n",
        "\n",
        "## !tensorboard dev delete --experiment_id YOUR_EXPERIMENT_ID_HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L68U_e3kg3K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm \"/content/gdrive/My Drive/SecondStage_colab/output/\" -rf\n",
        "!ls \"/content/gdrive/My Drive/SecondStage_colab/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLBsq6-_Q__U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/SecondStage_colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mw-VsAQoQwto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile label_map.pbtxt\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'red'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'orange'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 3\n",
        "  name: 'yellow'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 4\n",
        "  name: 'lime_green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 5\n",
        "  name: 'magenta' \n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 6\n",
        "  name: 'purple'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 7\n",
        "  name: 'green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 8\n",
        "  name: 'light_green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 9\n",
        "  name: 'blue_green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 10\n",
        "  name: 'light_blue'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 11\n",
        "  name: 'blue'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMu3CskmQxHq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%writefile label_map.pbtxt\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'red'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'yellow'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 3\n",
        "  name: 'lime_green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 4\n",
        "  name: 'magenta' \n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 5\n",
        "  name: 'purple'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 6\n",
        "  name: 'green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 7\n",
        "  name: 'blue_green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 8\n",
        "  name: 'light_blue'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 9\n",
        "  name: 'blue'\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#Fix problem with ros python path\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import dtypes\n",
    "from object_detection.data_decoders import tf_example_decoder\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE = '/media/data/LocalizationDataNew/data/dataset2/exp0/default_800x600.record'\n",
    "NUM_EXPORTS = 55\n",
    "\n",
    "PATH_TO_LABELS = '/media/data/Dokumente/Nextcloud/Studium/Bachelorarbeit/CNNRobotLocalisation/LabelMaps/robot_label_map.pbtxt'\n",
    "TMP_PATH = '/tmp/TFRecordInspector/'\n",
    "OUT_PATH = '/media/data/LocalizationDataNew/Output/TFRecordInspector/'\n",
    "os.makedirs(TMP_PATH, exist_ok=True)\n",
    "os.makedirs(OUT_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "num_labels = label_map_util.get_max_label_map_index(label_map)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_labels, use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_decoder_keys(decoder, example_key, dict_key, dt=tf.float32):\n",
    "    decoder.keys_to_features[example_key] = tf.VarLenFeature(dt)\n",
    "    decoder.items_to_handlers[dict_key] = slim_example_decoder.Tensor(example_key)\n",
    "    return decoder\n",
    "\n",
    "def calc_middle_bb(bb, width, height):\n",
    "    return ((bb[1]+bb[3])/2*width,(bb[0]+bb[2])/2*height)\n",
    "\n",
    "def visualize_orientation(img, bounding_box, theta, length = 100, thickness=2):\n",
    "    pos = calc_middle_bb(bounding_box, img.shape[1], img.shape[0])\n",
    "    xOff = math.sin(theta*np.pi/180)*length\n",
    "    yOff = math.cos(theta*np.pi/180)*length\n",
    "    cv2.arrowedLine(img, \\\n",
    "            (int(pos[0]+xOff),int(pos[1]+yOff)), \\\n",
    "            (int(pos[0]-xOff),int(pos[1]-yOff)), \\\n",
    "            (0,0,255),thickness)\n",
    "        \n",
    "sess = tf.InteractiveSession()\n",
    "slim_example_decoder = tf.contrib.slim.tfexample_decoder\n",
    "decoder = tf_example_decoder.TfExampleDecoder()\n",
    "decoder = extend_decoder_keys(decoder,'image/object/subclass/label','subclass_classes',tf.int64)\n",
    "decoder = extend_decoder_keys(decoder,'image/object/pose/orientation','orientation')\n",
    "decoder = extend_decoder_keys(decoder,'image/object/pose/iframe_w','iframe_w')\n",
    "decoder = extend_decoder_keys(decoder,'image/object/pose/iframe_h','iframe_h')\n",
    "decoder = extend_decoder_keys(decoder,'image/object/pose/dist_to_cam','dist_to_cam')\n",
    "\n",
    "i = -1\n",
    "for example in tf.python_io.tf_record_iterator(FILE):\n",
    "    i = i+1\n",
    "    if i > NUM_EXPORTS:\n",
    "        continue\n",
    "   \n",
    "    tf_dict = decoder.decode(example)\n",
    "    tf_dict = sess.run(tf_dict)\n",
    "    img = tf_dict['image']\n",
    "\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "        img,\n",
    "        tf_dict['groundtruth_boxes'],\n",
    "        tf_dict['subclass_classes'],\n",
    "        [1]*tf_dict['num_groundtruth_boxes'],\n",
    "        category_index,\n",
    "        use_normalized_coordinates=True,\n",
    "        line_thickness=4)\n",
    "    for bb,th in zip(tf_dict['groundtruth_boxes'], tf_dict['orientation']):\n",
    "        visualize_orientation(img, bb, th)\n",
    "\n",
    "    cv2.imwrite(OUT_PATH+'img{0:04d}-'.format(i)+tf_dict['filename'].decode('utf8'), cv2.cvtColor(img, cv2.COLOR_RGB2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster method of reading record; not integrated yet\n",
    "\n",
    "def read_int64(feature, key):\n",
    "    return int(feature[key].int64_list.value[0])\n",
    "\n",
    "record_iterator = tf.python_io.tf_record_iterator(PATH)\n",
    "\n",
    "for string_record in record_iterator:\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(string_record)\n",
    "    feat = example.features.feature\n",
    "    height = read_int64(feat,'image/height')\n",
    "    width = read_int64(feat,'image/width')\n",
    "    img_name = (feat['image/filename'].bytes_list.value[0]).decode('utf8')\n",
    "    img_enc = (feat['image/encoded'].bytes_list.value[0])\n",
    "    with tf.gfile.GFile(TMP_PATH+'tmp_img.jpg', 'wb') as fid:\n",
    "        fid.write(img_enc)\n",
    "        \n",
    "    img = Image.open(TMP_PATH+'tmp_img.jpg').convert('RGB')\n",
    "\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

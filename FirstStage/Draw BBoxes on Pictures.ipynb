{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TwoStageFramework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIyKlvTomhba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab.patches import cv2_imshow\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks/TwoStageFramework')\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/TwoStageFramework')\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import glob\n",
        "import copy\n",
        "import cv2\n",
        "\n",
        "#!wget https://github.com/wulfihm/rs_nn_training/raw/master/object_detector/working%20models/15022020_3x3Filter/frozen_inference_graph.pb\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
        "PATH_TO_CKPT = 'first_stage.pb'\n",
        "\n",
        "IMAGE_SIZE_FIRSTSTAGE = (400, 300)\n",
        "\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3CKR7XI2RCS",
        "colab_type": "text"
      },
      "source": [
        "First Stage Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYuUHcExmco_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filelist = glob.glob('images/*.png')\n",
        "\n",
        "cropped_images = []\n",
        "with detection_graph.as_default():\n",
        "  with tf.Session(graph=detection_graph) as sess:\n",
        "    for file in filelist:\n",
        "        image = cv2.imread(file, cv2.IMREAD_UNCHANGED)\n",
        "        image_res = cv2.resize(image, IMAGE_SIZE_FIRSTSTAGE)\n",
        "        # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
        "        image_np_expanded = np.expand_dims(image_res, axis=0)\n",
        "        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "        # Each box represents a part of the image where a particular object was detected.\n",
        "        boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "        # Each score represent how level of confidence for each of the objects.\n",
        "        # Score is shown on the result image, together with the class label.\n",
        "        scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "        classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "        # Actual detection.\n",
        "        (boxes, scores, classes, num_detections) = sess.run(\n",
        "            [boxes, scores, classes, num_detections],\n",
        "            feed_dict={image_tensor: image_np_expanded})\n",
        "        boxes_sq = np.squeeze(boxes)\n",
        "        scores_sq = np.squeeze(scores)\n",
        "        num_detections_sq = np.squeeze(num_detections)\n",
        "        image_colored = copy.deepcopy(image)\n",
        "        # Draw bounding boxes\n",
        "        color = np.array([0, 255, 0], dtype=np.uint8)\n",
        "        for i in range(0, int(num_detections_sq) - 1):\n",
        "            if scores_sq[i] > 0.3:\n",
        "                bbox = (int(boxes_sq[i, 0] * image.shape[0]), #xmin\n",
        "                                int((boxes_sq[i, 2]) * image.shape[0]), #xmax\n",
        "                                int(boxes_sq[i, 1] * image.shape[1]), #ymin\n",
        "                                int((boxes_sq[i, 3]) * image.shape[1])) #ymax\n",
        "                print(\"bbox dimensions: \" + str(bbox[1]-bbox[0]) + \"x\" + str(bbox[3]-bbox[2]))\n",
        "                image_colored[bbox[0], bbox[2]:bbox[3]] = color #obere kante\n",
        "                image_colored[bbox[1], bbox[2]:bbox[3]] = color #unter kante\n",
        "                image_colored[bbox[0]:bbox[1], bbox[2]] = color #linke kante\n",
        "                image_colored[bbox[0]:bbox[1], bbox[3]] = color #rechte kante\n",
        "                \n",
        "                crop_img = image[bbox[0]:bbox[1], bbox[2]:bbox[3]]\n",
        "                cropped_images.append(crop_img)\n",
        "                cv2_imshow(crop_img)\n",
        "        cv2_imshow(image_colored)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci3Eu-N3Vf8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "\n",
        "%tensorboard --logdir \"logs\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
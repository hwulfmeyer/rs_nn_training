{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondStage2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJlG_lwKEaQv",
        "colab_type": "text"
      },
      "source": [
        "to do:\n",
        "- image in tensorboard (test alpha mobilenet)\n",
        "- imports aufräumen\n",
        "- Secondstage.py & second_stage_utils.py importieren\n",
        "- ss_utils -> Bild öffnen\n",
        "- Konfiguration außerhalb:\n",
        "    - Name output\n",
        "    - cat/ bin/ reg\n",
        "- endliche Anzahl an Runden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHIKxNY3oahf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VO6zc_v7lJ-",
        "colab_type": "text"
      },
      "source": [
        "von Tobi geklaut\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_HjEoWRonVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FH4BMdyyorVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85f2szA_pAJg",
        "colab_type": "code",
        "outputId": "5e29e51b-a0aa-4b50-ea50-141f868fee24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%cd models/research"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPwg_kkapFJg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fsskp5qWpJRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJLXPuYIpNg4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python object_detection/builders/model_builder_test.py"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "japGTz-bFnCC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ef436eb8-f706-4fcf-8774-c96e01af88bb"
      },
      "source": [
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5h9RbyaYC-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "sys.path.append('/content/gdrive/My Drive/SecondStage_colab/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZWtkiVKShNH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/SecondStage_colab/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exoPdhiJ7p1R",
        "colab_type": "text"
      },
      "source": [
        "Second Stage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwRKHys0KBHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NAME =\n",
        "#example: cat_exptype_dataset(training)_dataset(eval)_conf(batch size etc) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqzYclgV64T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_PATH = '/content/gdrive/My Drive/SecondStage_colab/output/'\n",
        "LABEL_MAP_PATH = '/content/gdrive/My Drive/SecondStage_colab/label_map.pbtxt'\n",
        "TRAIN_RECORD = '/content/gdrive/My Drive/data/train/training_rot15_32400.tfrecords'\n",
        "EVAL_RECORD = '/content/gdrive/My Drive/data/test/sphero/sphero_evaluation_rot2_4320_.tfrecords'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjrsBWe_7sjQ",
        "colab_type": "code",
        "outputId": "fe322880-f98c-4811-c681-b2fab04e9a74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/')\n",
        "\n",
        "from SecondStage_colab import second_stage_utils\n",
        "from SecondStage_colab import file_utils"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKaABMtXB-OA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/models/research')\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vu6XjokkxhSx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#os.environ['PYTHONPATH'] += ':/contentdrive/My Drive/SecondStage_colab/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7R7pUpyVcHIf",
        "colab_type": "text"
      },
      "source": [
        "configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1i_AkgfcGUv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "GPU = True\n",
        "BATCH_SIZE = 1024\n",
        "\n",
        "ANGLES_PER_BIN = 1\n",
        "NUM_ORI_BINS = 360"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7Hbp0ghcZtB",
        "colab_type": "text"
      },
      "source": [
        "label map\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk0ZiaTCthBu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/gdrive/My Drive/SecondStage_colab')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOwjdrteceEe",
        "colab_type": "code",
        "outputId": "2765c766-8fa7-4553-d782-234e0d4e4807",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile label_map.pbtxt\n",
        "\n",
        "item {\n",
        "  id: 1\n",
        "  name: 'bright_blue'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 2\n",
        "  name: 'bright_red'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 3\n",
        "  name: 'bright_green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 4\n",
        "  name: 'bright_white'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 5\n",
        "  name: 'dark_blue'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 6\n",
        "  name: 'dark_green'\n",
        "}\n",
        "\n",
        "item {\n",
        "  id: 7\n",
        "  name: 'dark_red'\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting label_map.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5-N8oYNQ_8C",
        "colab_type": "text"
      },
      "source": [
        "experiment definitioin\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmm4SaY3QXt3",
        "colab_type": "code",
        "outputId": "67f466ac-ef9f-41eb-bdde-8a1ed2df1977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%%writefile exp_def.py\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "default_sstage_conf = {\n",
        "    'dataset': 'default',\n",
        "    'types': ['copter','sphero','youbot'],\n",
        "    # converged after 15 / 10 / 5 epochs\n",
        "    # 10 epochs after convergance for evaluation phase\n",
        "    'epochs_cat': 25,\n",
        "    #'epochs_reg': 20,\n",
        "    'epochs_reg': 50,\n",
        "    'epochs_bin': 15,\n",
        "    'optimizer': 'adam',\n",
        "    'learning_rate': 3e-4,\n",
        "    'dropout': 0,\n",
        "    'alpha': 0.5,\n",
        "    'img_size': 35,\n",
        "    'separate_cat_ori': True,\n",
        "    'cat_weight': 1.0,\n",
        "    'reg_weight': 1.0,\n",
        "    'bin_weight': 1.0,\n",
        "    'enable_reg': False,\n",
        "    'enable_bin': True,\n",
        "    'repetions': 4,\n",
        "}\n",
        "\n",
        "def create_all_sstage_experiments():\n",
        "    configs = []\n",
        "    configs.extend(create_sstage_default())\n",
        "\n",
        "    return configs\n",
        "\n",
        "def create_sstage_default():\n",
        "    config = []\n",
        "    modified = deepcopy(default_sstage_conf)\n",
        "    modified['name'] = \"sstage_default\"\n",
        "    modified['enable_reg'] = True\n",
        "    config.append(deepcopy(modified))\n",
        "    return config"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting exp_def.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDJatt09QfGq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm\n",
        "import re\n",
        "from datetime import datetime\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from keras import applications\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Reshape, Conv2D, Activation\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\n",
        "from keras.models import load_model\n",
        "from keras.utils import np_utils\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "import csv, json, pickle\n",
        "from lxml import etree\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJTQhRbOVOFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_square(im, size, fill_color=(0, 0, 0, 0)):\n",
        "    x, y = im.size\n",
        "    scl = size/max(x, y)\n",
        "    im = im.resize((int(x*scl),int(y*scl)))\n",
        "    new_im = Image.new('RGB', (size, size), fill_color)\n",
        "    new_im.paste(im, (int((size - im.size[0]) / 2), int((size - im.size[1]) / 2)))\n",
        "    return new_im\n",
        "\n",
        "def angle_diff2(y_true, y_pred):\n",
        "    return tf.mod(( (y_true - y_pred) + 180 ), 360 ) - 180\n",
        "\n",
        "def np_angle_diff2(y_true, y_pred):\n",
        "    return np.mod(( (y_true - y_pred) + 180 ), 360 ) - 180\n",
        "\n",
        "def angle_mae(y_true, y_pred):\n",
        "    return K.mean(K.abs(angle_diff2(y_true, y_pred)), axis=-1)\n",
        "\n",
        "def angle_mse(y_true, y_pred):\n",
        "    return K.mean(K.square(angle_diff2(y_true, y_pred)), axis=-1)\n",
        "\n",
        "def angle_bin_error(y_true, y_pred):\n",
        "    diff = angle_diff2(K.argmax(y_true)*ANGLES_PER_BIN,\n",
        "                       K.argmax(y_pred)*ANGLES_PER_BIN)\n",
        "    return K.mean(K.cast(K.abs(diff), K.floatx()))\n",
        "\n",
        "def data_to_keras(X,Y,Z, num_classes, size=35):\n",
        "    X = [np.asarray(e) for e in X]\n",
        "\n",
        "    X = np.asarray(X, dtype=\"uint8\")\n",
        "    X = X.reshape(X.shape[0], size, size, 3)\n",
        "    X.astype('float32')\n",
        "    #X /= 255\n",
        "    Y = np.asarray(Y)\n",
        "    Y = np_utils.to_categorical(Y, num_classes)\n",
        "    Z = np.asarray(Z)\n",
        "    return X,Y,Z\n",
        "\n",
        "def angle_to_bin(Z):\n",
        "    Z = np.mod(Z, 360)\n",
        "    return np_utils.to_categorical(np.floor(Z/ANGLES_PER_BIN),NUM_ORI_BINS)\n",
        "\n",
        "\"\"\"\n",
        "img_enc = (feats.feature['image/encoded'].bytes_list.value[0]).decode('utf-8')\n",
        "img_name = (feats.feature['image/filename'].bytes_list.value[0]).decode('utf-8')\n",
        "filename = (feats.feature['image/filename'].bytes_list.value[0]).decode('utf-8')\n",
        "source_id = (feats.feature['image/source_id'].bytes_list.value[0]).decode('utf-8')\n",
        "width = feats.feature['image/width'].int64_list.value[0]\n",
        "height = feats.feature['image/height'].int64_list.value[0]\n",
        "class = (feats.feature['image/object/class/text'].bytes_list.value[0]).decode('utf-8')\n",
        "class_label = feats.feature['image/object/class/label'].int64_list.value[0]\n",
        "color = (feats.feature['image/object/subclass/text'].bytes_list.value[0]).decode('utf-8')\n",
        "color_id = feats.feature['image/object/subclass/label'].int64_list.value[0]\n",
        "orientation = feats.feature['image/object/pose/orientation'].int64_list.value[0]\n",
        "\"\"\"\n",
        "\n",
        "def tf_record_load_crops(files,num_per_record=-1,size=35):\n",
        "    crops, classes, orientations = [],[],[]\n",
        "    debug_infos = []\n",
        "    for f in files:\n",
        "        record_iterator = tf.python_io.tf_record_iterator(f)\n",
        "        #records = tf.data.TFRecordDataset(f)\n",
        "        for l, string_record in enumerate(record_iterator):\n",
        "        #for string_record in records:\n",
        "            if num_per_record!=-1 and l > num_per_record: break\n",
        "            example = tf.train.Example()\n",
        "            example.ParseFromString(string_record)#.numpy())\n",
        "            feats = example.features\n",
        "\n",
        "            img_enc = (feats.feature['image/encoded'].bytes_list.value[0])#.decode('utf-8')\n",
        "\n",
        "            img_name = (feats.feature['image/filename'].bytes_list.value[0]).decode('utf-8')\n",
        "            img_enc = (feats.feature['image/encoded'].bytes_list.value[0]) #.decode('utf-8')\n",
        "            width = feats.feature['image/width'].int64_list.value[0]\n",
        "            height = feats.feature['image/height'].int64_list.value[0]\n",
        "\n",
        "            img = Image.frombytes('RGB', (height, width), img_enc)\n",
        "            #img = Image.open(io.BytesIO(img_enc))\n",
        "\n",
        "            color = (feats.feature[\"image/object/subclass/text\"].bytes_list.value[0]).decode('utf-8') \n",
        "            color_id = feats.feature[\"image/object/subclass/label\"].int64_list.value[0]\n",
        "            orientation = feats.feature[\"image/object/pose/orientation\"].int64_list.value[0]\n",
        "\n",
        "            crops.append(make_square(img,size))\n",
        "            classes.append(color_id)\n",
        "            orientations.append(orientation)\n",
        "            debug_infos.append({\n",
        "                'filename': img_name,\n",
        "                'src_record': f\n",
        "            })\n",
        "\n",
        "    assert len(crops) == len(classes) and len(crops) == len(orientations)\n",
        "    print(\"Loaded {} crops from {}\".format(len(crops),files))\n",
        "\n",
        "    return crops, classes, orientations, debug_infos\n",
        "\n",
        "def custom_randint(min, max):\n",
        "    min = round(min)\n",
        "    max = round(max)\n",
        "    if min == max:\n",
        "        return min\n",
        "    return randint(min, max)\n",
        "\n",
        "def tf_record_extract_crops(files, num_derivations,\n",
        "                            out_var, in_var,\n",
        "                            num_per_record=-1,\n",
        "                            size=35,\n",
        "                            class_filters=None):\n",
        "    crops, classes, orientations = [],[],[]\n",
        "    debug_infos = []\n",
        "    for f in files:\n",
        "        record_iterator = tf.python_io.tf_record_iterator(f)\n",
        "        for l, string_record in enumerate(record_iterator):\n",
        "            if num_per_record!=-1 and l > num_per_record: break\n",
        "            example = tf.train.Example()\n",
        "            example.ParseFromString(string_record) #.numpy())\n",
        "            feats = example.features\n",
        "            width  = feats.feature[\"image/width\"].int64_list.value[0]\n",
        "            height = feats.feature[\"image/height\"].int64_list.value[0]\n",
        "            #width = 35\n",
        "            #height = 35\n",
        "            img_name = (feats.feature['image/filename'].bytes_list.value[0]).decode('utf8')\n",
        "            img_enc = (feats.feature['image/encoded'].bytes_list.value[0])\n",
        "            #img = Image.open(io.BytesIO(img_enc))\n",
        "            #img = Image.open(open(img_enc, \"rb\"))\n",
        "            img = Image.frombytes('RGB', (height, width), img_enc)\n",
        "\n",
        "            for i,_ in enumerate(feats.feature[\"image/object/class/text\"].bytes_list.value):\n",
        "                class_text = (feats.feature[\"image/object/subclass/text\"].bytes_list.value[i]).decode('utf8')\n",
        "                if not (class_filters == None or any(m in class_text for m in class_filters)):\n",
        "                    continue\n",
        "                class_label = feats.feature[\"image/object/subclass/label\"].int64_list.value[i]\n",
        "                orientation = feats.feature[\"image/object/pose/orientation\"].int64_list.value[i]\n",
        "                width = feats.feature['image/width'].int64_list.value[0]\n",
        "                height = feats.feature['image/height'].int64_list.value[0]                \n",
        " \n",
        "                img_resized = img;\n",
        "                if (width != 35 or height != 35): \n",
        "                    img_resized = img.resize((35,35), Image.BICUBIC)\n",
        "\n",
        "                crops.append(make_square(img_resized,size))\n",
        "                classes.append(class_label)\n",
        "                orientations.append(orientation)\n",
        "                debug_infos.append({\n",
        "                    'filename': img_name,\n",
        "                    'src_record': f,\n",
        "                    'crop_num': i*num_derivations,\n",
        "                })\n",
        "            img.close()\n",
        "\n",
        "    return crops, classes, orientations, debug_infos\n",
        "\n",
        "from keras.callbacks import Callback\n",
        "import sklearn.metrics as sklm\n",
        "class TensorBoardCustom(Callback):\n",
        "    def __init__(self, log_dir='./logs',label_map='',images=''):\n",
        "        super(Callback, self).__init__()\n",
        "        global tf, projector\n",
        "        try:\n",
        "            import tensorflow as tf\n",
        "            from tensorflow.contrib.tensorboard.plugins import projector\n",
        "        except ImportError:\n",
        "            raise ImportError('You need the TensorFlow module installed to use TensorBoard.')\n",
        "\n",
        "        self.log_dir = log_dir\n",
        "        self.label_map = label_map\n",
        "        self.images = images\n",
        "\n",
        "    def set_model(self, model):\n",
        "        self.model = model\n",
        "        if K.backend() == 'tensorflow':\n",
        "            self.sess = K.get_session()\n",
        "        self.merged = tf.summary.merge_all()\n",
        "        self.writer = tf.summary.FileWriter(self.log_dir)\n",
        "\n",
        "    def write_metric(self, name, value, epoch, namespace=''):\n",
        "        if namespace != '':\n",
        "            namespace += '/'\n",
        "        summary = tf.Summary(value=[\n",
        "            tf.Summary.Value(tag=namespace+name, simple_value=value),\n",
        "        ])\n",
        "        self.writer.add_summary(summary, epoch)\n",
        "\n",
        "    def add_custom_metrics(self, epoch):\n",
        "        y_pred, z_pred, z2_pred = self.model.predict(self.validation_data[0])\n",
        "        # [1] -> Y; [2] -> Z\n",
        "        y_targ = self.validation_data[1]\n",
        "        y_targ_onehot = np.argmax(y_targ, axis=1)\n",
        "        y_pred_onehot = np.argmax(y_pred, axis=1)\n",
        "\n",
        "        class_prec, class_rec, class_f1, class_support = sklm.precision_recall_fscore_support(\n",
        "            y_targ_onehot,\n",
        "            y_pred_onehot,\n",
        "            labels=[int(e) for e in self.label_map.keys()]\n",
        "        )\n",
        "        for i, (prec, rec, f1, sup) in enumerate(zip(class_prec,\n",
        "                                                   class_rec,\n",
        "                                                   class_f1,\n",
        "                                                   class_support)):\n",
        "            i+=1\n",
        "            if self.label_map == '':\n",
        "                label = str(i)\n",
        "            elif i in self.label_map:\n",
        "                label = str(i) +' '+ self.label_map[i]['name']\n",
        "            else:\n",
        "                label = str(i)\n",
        "            if sup > 0:\n",
        "                namespace = \"Precision by Category/{}\".format(label)\n",
        "                self.write_metric('Precision', prec, epoch, namespace)\n",
        "                namespace = \"Recall by Category/{}\".format(label)\n",
        "                self.write_metric('Recall', rec, epoch, namespace)\n",
        "                namespace = \"F1 by Category/{}\".format(label)\n",
        "                self.write_metric('F1', f1, epoch, namespace)\n",
        "            if epoch == 0:\n",
        "                namespace = \"Support by Category/{}\".format(label)\n",
        "                self.write_metric('Support', sup, epoch, namespace)\n",
        "        # average='weighted'\n",
        "        # Calculate metrics for each label, and find their average\n",
        "        # -> balanced\n",
        "        avg_prec, avg_rec, avg_f1, avg_support = sklm.precision_recall_fscore_support(\n",
        "            y_targ_onehot,\n",
        "            y_pred_onehot,\n",
        "            average='weighted'\n",
        "        )\n",
        "        self.write_metric('Average Precision', avg_prec, epoch, 'Average Performance')\n",
        "        self.write_metric('Average Recall', avg_rec, epoch, 'Average Performance')\n",
        "        self.write_metric('Average F1', avg_f1, epoch, 'Average Performance')\n",
        "        self.write_metric('Average Support', avg_support, epoch, 'Average Performance')\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        for name, value in logs.items():\n",
        "            if name in ['batch', 'size']:\n",
        "                continue\n",
        "            # summary = tf.Summary()\n",
        "            # summary_value = summary.value.add()\n",
        "            # summary_value.simple_value = value.item()\n",
        "            # summary_value.tag = name\n",
        "            if 'val' in name:\n",
        "                group = 'Keras Validation/'\n",
        "            else:\n",
        "                group = 'Keras Training/'\n",
        "            self.write_metric(name, value, epoch, group)\n",
        "\n",
        "        # self.add_custom_metrics(epoch)\n",
        "\n",
        "        self.writer.flush()\n",
        "\n",
        "    def on_train_end(self, _):\n",
        "        self.writer.close()\n",
        "\n",
        "\n",
        "import unittest\n",
        "\n",
        "class TestSecondStageUtils(unittest.TestCase):\n",
        "\n",
        "    def test_np_angle_diff2(self):\n",
        "        self.assertEqual(np_angle_diff2(359,52), -53)\n",
        "        self.assertEqual(np_angle_diff2(52,359), 53)\n",
        "        self.assertEqual(np_angle_diff2(0,720), 0)\n",
        "\n",
        "    def test_angle_to_bin(self):\n",
        "        self.assertEqual(len(angle_to_bin(4)), 90)\n",
        "        self.assertEqual(angle_to_bin(4)[0], 0)\n",
        "        self.assertEqual(angle_to_bin(4)[1], 1)\n",
        "        for i in range(2,90):\n",
        "            self.assertEqual(angle_to_bin(4)[i], 0)\n",
        "        self.assertEqual(angle_to_bin(50)[12], 1)\n",
        "        self.assertEqual(angle_to_bin(360)[0], 1)\n",
        "        self.assertEqual(angle_to_bin(370)[2], 1)\n",
        "        self.assertEqual(angle_to_bin(-10)[87], 1)\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#    unittest.main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG9YYdriX8WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(train_record, conf, types, out, rep=1):\n",
        "\n",
        "    #from SecondStage_colab.file_utils import *\n",
        "    from file_utils import save_json\n",
        "\n",
        "    timestamp = \"{:%Y-%m-%d-%H-%M}\".format(datetime.now())\n",
        "    log_path = LOG_PATH + conf['name'] + '_' + \\\n",
        "                ''.join(types) + out + '/' + \\\n",
        "                timestamp + '-r' + str(rep) + '/'\n",
        "    os.makedirs(log_path, exist_ok=True)\n",
        "    save_json(log_path + '/experiment_config.json', conf)\n",
        "\n",
        "    label_map = label_map_util.create_category_index_from_labelmap(LABEL_MAP_PATH)\n",
        "    #label_map = create_category_index_from_labelmap(LABEL_MAP_PATH)\n",
        "\n",
        "    num_classes = label_map_util.get_max_label_map_index(\n",
        "                           label_map_util.load_labelmap(LABEL_MAP_PATH)) + 1\n",
        "\n",
        "    X,Y,Z,_ = tf_record_load_crops([train_record])\n",
        "    X_train, Y_train, Z_train = data_to_keras(X,Y,Z,num_classes,conf['img_size'])\n",
        "    Z2_train = angle_to_bin(Z_train)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "    print(Y_train.shape)\n",
        "    print(num_classes)\n",
        "    print(Z2_train.shape)\n",
        "    print(NUM_ORI_BINS)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "\n",
        "    eval_records = EVAL_RECORD\n",
        "\n",
        "    X,Y,Z,_ = tf_record_extract_crops([eval_records], 1, 0.0, 0.0)\n",
        "    X_val, Y_val, Z_val = data_to_keras(X,Y,Z,num_classes,conf['img_size'])\n",
        "    Z2_val = angle_to_bin(Z_val)\n",
        "\n",
        "    assert len(X_val) > 0 and len(Y_val) > 0 and len(Z_val) > 0, \\\n",
        "        '{} is incomplete'.format(eval_records)\n",
        "    mobilenet_base = applications.mobilenet.MobileNet(alpha = conf['alpha'],\n",
        "                                                      weights = \"imagenet\",\n",
        "                                                      include_top=False,\n",
        "                                                      input_shape = (\n",
        "                                                      conf['img_size'],\n",
        "                                                      conf['img_size'],\n",
        "                                                        3\n",
        "                                                      ))\n",
        "    shape = (1, 1, int(1024 * conf['alpha']))\n",
        "    x = GlobalAveragePooling2D()(mobilenet_base.output)\n",
        "    x = Reshape(shape, name='reshape_1')(x)\n",
        "    x = Dropout(conf['dropout'], name='dropout')(x)\n",
        "    # Branch regression\n",
        "    reg = Conv2D(1, (1, 1),\n",
        "               padding='same', name='conv_reg')(x)\n",
        "    reg = Activation('linear', name='act_linear')(reg)\n",
        "    reg = Reshape((1,), name='reg_out')(reg)\n",
        "    # Branch orientation classification with bins\n",
        "    bin = Conv2D(NUM_ORI_BINS, (1, 1),\n",
        "               padding='same', name='conv_bin')(x)\n",
        "    bin = Activation('softmax', name='act_bin')(bin)\n",
        "    bin = Reshape((NUM_ORI_BINS,), name='bin_out')(bin)\n",
        "    # Branch classification\n",
        "    cat = Conv2D(num_classes, (1, 1),\n",
        "               padding='same', name='conv_cat')(x)\n",
        "    cat = Activation('softmax', name='act_softmax')(cat)\n",
        "    cat = Reshape((num_classes,), name='cat_out')(cat)\n",
        "\n",
        "    # creating the final model\n",
        "    model_final = None\n",
        "    model_final = Model(inputs = mobilenet_base.input, outputs = [cat,reg,bin])\n",
        "\n",
        "    if conf['optimizer'] == 'rmsprop':\n",
        "        optimizer = optimizers.RMSprop(lr=conf['learning_rate'])\n",
        "    elif conf['optimizer'] == 'adam':\n",
        "        optimizer = optimizers.Adam(lr=conf['learning_rate'])\n",
        "    else:\n",
        "        raise Error('Unknown optimizer: ' + conf['optimizer'])\n",
        "\n",
        "    model_final.compile(optimizer = optimizer,\n",
        "                        loss={'cat_out': 'categorical_crossentropy',\n",
        "                              'reg_out': angle_mse,\n",
        "                              'bin_out': 'categorical_crossentropy',\n",
        "                        },\n",
        "                        loss_weights={'cat_out': conf['cat_weight'],\n",
        "                                      'reg_out': conf['reg_weight'],\n",
        "                                      'bin_out': conf['bin_weight']},\n",
        "                        metrics ={'cat_out': 'accuracy',\n",
        "                                  'reg_out': angle_mae,\n",
        "                                  'bin_out': angle_bin_error})\n",
        "\n",
        "    ###########\n",
        "\n",
        "    img = np.reshape(X_train[0], (-1, 35, 35, 1))\n",
        "    !rm -rf logs\n",
        "    logdir = LOG_PATH + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    #file_writer = tf.summary.create_file_writer(logdir)\n",
        "    file_writer = tf.compat.v1.summary.FileWriter(logdir)\n",
        "    with file_writer: #.as_default():\n",
        "      #tf.summary.image(\"Training data\", img, step=0)\n",
        "      tf.compat.v1.summary.image(\"Training data\", img) #, step=0)\n",
        "\n",
        "\n",
        "    ########\n",
        "\n",
        "    summary = TensorBoardCustom(log_dir=log_path,label_map=label_map)\n",
        "    filepath=log_path+\"model-{epoch:02d}.h5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, verbose=1, period=5)\n",
        "\n",
        "    model_final.fit(\n",
        "        X_train,\n",
        "        {'cat_out': Y_train, 'reg_out': Z_train, 'bin_out': Z2_train},\n",
        "        validation_data=(X_val,[Y_val,Z_val, Z2_val]),\n",
        "        batch_size=BATCH_SIZE, epochs=conf['epochs'], verbose=0,\n",
        "        callbacks=[summary,checkpoint],\n",
        "        shuffle=True\n",
        "    )\n",
        "    model_final.save(log_path+\"model-final.h5\")\n",
        "    print(\"Finished training for {}_{}\".format(conf['name'],t))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjhzN9oBxzHc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from SecondStage_colab import exp_def\n",
        "from copy import deepcopy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jru6gJiHAVl",
        "colab_type": "code",
        "outputId": "e379f1b3-82c5-4932-980d-c6a90cf4c0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "exp = exp_def.create_all_sstage_experiments()\n",
        "for or_conf in tqdm(exp):\n",
        "    print(\"or_conf\", or_conf)\n",
        "    for r in range(or_conf['repetions']): \n",
        "        #train_records = get_recursive_file_list(TRAIN_DIR,file_matchers=[or_conf['dataset']])\n",
        "        train_records = [TRAIN_RECORD]\n",
        "        for t in or_conf['types']:\n",
        "            for out in ['_cat','_reg','_bin','']:\n",
        "                conf = deepcopy(or_conf)\n",
        "                train_instance_name = conf['name']+'_'+t+out\n",
        "                if not conf['separate_cat_ori'] and out != '':\n",
        "                    continue\n",
        "                if conf['separate_cat_ori']:\n",
        "                    if out == '':\n",
        "                        continue\n",
        "                    elif out == '_cat':\n",
        "                        conf['reg_weight'] = 0.0\n",
        "                        conf['bin_weight'] = 0.0\n",
        "                        conf['epochs'] = conf['epochs_cat']\n",
        "                    elif out == '_reg' and conf['enable_reg']:\n",
        "                        conf['cat_weight'] = 0.0\n",
        "                        conf['bin_weight'] = 0.0\n",
        "                        conf['epochs'] = conf['epochs_reg']\n",
        "                    elif out == '_bin' and conf['enable_bin']:\n",
        "                        conf['cat_weight'] = 0.0\n",
        "                        conf['reg_weight'] = 0.0\n",
        "                        conf['epochs'] = conf['epochs_bin']\n",
        "                    else:\n",
        "                        print('UNKNOWN OUTPUT CONFIG {}'.format(out))\n",
        "                        continue\n",
        "                if not re.match('sstage_default_sphero_reg', train_instance_name): \n",
        "                    print('Skip '+train_instance_name)\n",
        "                    continue            \n",
        "                #record_for_type = [e for e in train_records if t in e]\n",
        "                #print(\"record_for_type: \", len(record_for_type))\n",
        "                #assert len(record_for_type) == 1, \\\n",
        "                #       \"{} for {} has not one item\".format(record_for_type, train_instance_name)\n",
        "                print(\"Start training\")\n",
        "                \n",
        "                if not GPU:\n",
        "                    p = Process(\n",
        "                      target=train,\n",
        "                      args=(train_records[0], conf, ['sphero'], out, r)\n",
        "                    )\n",
        "                    p.start() \n",
        "                else:\n",
        "                 \n",
        "                  train(train_records[0], conf, ['sphero'], out)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "or_conf {'dataset': 'default', 'types': ['copter', 'sphero', 'youbot'], 'epochs_cat': 25, 'epochs_reg': 50, 'epochs_bin': 15, 'optimizer': 'adam', 'learning_rate': 0.0003, 'dropout': 0, 'alpha': 0.5, 'img_size': 35, 'separate_cat_ori': True, 'cat_weight': 1.0, 'reg_weight': 1.0, 'bin_weight': 1.0, 'enable_reg': True, 'enable_bin': True, 'repetions': 4, 'name': 'sstage_default'}\n",
            "Skip sstage_default_copter_cat\n",
            "Skip sstage_default_copter_reg\n",
            "Skip sstage_default_copter_bin\n",
            "Skip sstage_default_sphero_cat\n",
            "Start training\n",
            "Loaded 32400 crops from ['/content/gdrive/My Drive/data/train/training_rot15_32400.tfrecords']\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n",
            "(32400, 8)\n",
            "8\n",
            "(32400, 360)\n",
            "360\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Summary name Training data is illegal; using Training_data instead.\n",
            "\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-05.h5\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-10.h5\n",
            "\n",
            "Epoch 00015: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-15.h5\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-20.h5\n",
            "\n",
            "Epoch 00025: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-25.h5\n",
            "\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-30.h5\n",
            "\n",
            "Epoch 00035: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-35.h5\n",
            "\n",
            "Epoch 00040: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-40.h5\n",
            "\n",
            "Epoch 00045: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-45.h5\n",
            "\n",
            "Epoch 00050: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-13-r1/model-50.h5\n",
            "Finished training for sstage_default_sphero\n",
            "Skip sstage_default_sphero_bin\n",
            "Skip sstage_default_youbot_cat\n",
            "Skip sstage_default_youbot_reg\n",
            "Skip sstage_default_youbot_bin\n",
            "Skip sstage_default_copter_cat\n",
            "Skip sstage_default_copter_reg\n",
            "Skip sstage_default_copter_bin\n",
            "Skip sstage_default_sphero_cat\n",
            "Start training\n",
            "Loaded 32400 crops from ['/content/gdrive/My Drive/data/train/training_rot15_32400.tfrecords']\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n",
            "(32400, 8)\n",
            "8\n",
            "(32400, 360)\n",
            "360\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Summary name Training data is illegal; using Training_data instead.\n",
            "\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-05.h5\n",
            "\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-10.h5\n",
            "\n",
            "Epoch 00015: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-15.h5\n",
            "\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-20.h5\n",
            "\n",
            "Epoch 00025: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-25.h5\n",
            "\n",
            "Epoch 00030: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-30.h5\n",
            "\n",
            "Epoch 00035: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-35.h5\n",
            "\n",
            "Epoch 00040: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-40.h5\n",
            "\n",
            "Epoch 00045: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-45.h5\n",
            "\n",
            "Epoch 00050: saving model to /content/gdrive/My Drive/SecondStage_colab/output/sstage_default_sphero_reg/2020-01-14-20-17-r1/model-50.h5\n",
            "Finished training for sstage_default_sphero\n",
            "Skip sstage_default_sphero_bin\n",
            "Skip sstage_default_youbot_cat\n",
            "Skip sstage_default_youbot_reg\n",
            "Skip sstage_default_youbot_bin\n",
            "Skip sstage_default_copter_cat\n",
            "Skip sstage_default_copter_reg\n",
            "Skip sstage_default_copter_bin\n",
            "Skip sstage_default_sphero_cat\n",
            "Start training\n",
            "Loaded 32400 crops from ['/content/gdrive/My Drive/data/train/training_rot15_32400.tfrecords']\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n",
            "(32400, 8)\n",
            "8\n",
            "(32400, 360)\n",
            "360\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Summary name Training data is illegal; using Training_data instead.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-7447cf1a7226>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_records\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'sphero'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-22371296661c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_record, conf, types, out, rep)\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     )\n\u001b[1;32m    111\u001b[0m     \u001b[0mmodel_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"model-final.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2931\u001b[0m                                 \u001b[0mfeed_symbols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2932\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2933\u001b[0;31m                                 session)\n\u001b[0m\u001b[1;32m   2934\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_make_callable\u001b[0;34m(self, feed_arrays, feed_symbols, symbol_vals, session)\u001b[0m\n\u001b[1;32m   2883\u001b[0m             \u001b[0mcallable_opts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2884\u001b[0m         \u001b[0;31m# Create callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2885\u001b[0;31m         \u001b[0mcallable_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_callable_from_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_opts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2886\u001b[0m         \u001b[0;31m# Cache parameters corresponding to the generated callable, so that\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2887\u001b[0m         \u001b[0;31m# we can detect future mismatches and refresh the callable.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_make_callable_from_options\u001b[0;34m(self, callable_options)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \"\"\"\n\u001b[1;32m   1504\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1505\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mBaseSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallable_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1506\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, session, callable_options)\u001b[0m\n\u001b[1;32m   1458\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m         self._handle = tf_session.TF_SessionMakeCallable(\n\u001b[0;32m-> 1460\u001b[0;31m             session._session, options_ptr)\n\u001b[0m\u001b[1;32m   1461\u001b[0m       \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_DeleteBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondStage2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJlG_lwKEaQv",
        "colab_type": "text"
      },
      "source": [
        "to do:\n",
        "- image in tensorboard (test alpha mobilenet)\n",
        "- imports aufräumen\n",
        "- Secondstage.py\n",
        "- Konfiguration außerhalb:\n",
        "    - Name output\n",
        "    - cat/ bin/ reg\n",
        "- endliche Anzahl an Runden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BcJ4A6G0rjB",
        "colab_type": "code",
        "outputId": "30bc3dad-bd7d-45c8-8958-45448374e405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install tensorflow==1.14\n",
        "\n",
        "!git clone --quiet https://github.com/tensorflow/models.git\n",
        "!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk\n",
        "!pip install -q Cython contextlib2 pillow lxml matplotlib\n",
        "!pip install -q pycocotools\n",
        "\n",
        "%cd models/research\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util\n",
        "\n",
        "import os\n",
        "os.environ['PYTHONPATH'] += ':/content/models/research/:/content/models/research/slim/'\n",
        "!python object_detection/builders/model_builder_test.py\n",
        "\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n",
            "\u001b[K     |████████████████████████████████| 109.2MB 28kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.12.0)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n",
            "\u001b[K     |████████████████████████████████| 491kB 38.0MB/s \n",
            "\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.11.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.14) (1.17.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.14) (45.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (0.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.1.1)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n",
            "Selecting previously unselected package python-bs4.\n",
            "(Reading database ... 145155 files and directories currently installed.)\n",
            "Preparing to unpack .../0-python-bs4_4.6.0-1_all.deb ...\n",
            "Unpacking python-bs4 (4.6.0-1) ...\n",
            "Selecting previously unselected package python-pkg-resources.\n",
            "Preparing to unpack .../1-python-pkg-resources_39.0.1-2_all.deb ...\n",
            "Unpacking python-pkg-resources (39.0.1-2) ...\n",
            "Selecting previously unselected package python-chardet.\n",
            "Preparing to unpack .../2-python-chardet_3.0.4-1_all.deb ...\n",
            "Unpacking python-chardet (3.0.4-1) ...\n",
            "Selecting previously unselected package python-six.\n",
            "Preparing to unpack .../3-python-six_1.11.0-2_all.deb ...\n",
            "Unpacking python-six (1.11.0-2) ...\n",
            "Selecting previously unselected package python-webencodings.\n",
            "Preparing to unpack .../4-python-webencodings_0.5-2_all.deb ...\n",
            "Unpacking python-webencodings (0.5-2) ...\n",
            "Selecting previously unselected package python-html5lib.\n",
            "Preparing to unpack .../5-python-html5lib_0.999999999-1_all.deb ...\n",
            "Unpacking python-html5lib (0.999999999-1) ...\n",
            "Selecting previously unselected package python-lxml:amd64.\n",
            "Preparing to unpack .../6-python-lxml_4.2.1-1ubuntu0.1_amd64.deb ...\n",
            "Unpacking python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python-olefile.\n",
            "Preparing to unpack .../7-python-olefile_0.45.1-1_all.deb ...\n",
            "Unpacking python-olefile (0.45.1-1) ...\n",
            "Selecting previously unselected package python-pil:amd64.\n",
            "Preparing to unpack .../8-python-pil_5.1.0-1_amd64.deb ...\n",
            "Unpacking python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-pkg-resources (39.0.1-2) ...\n",
            "Setting up python-six (1.11.0-2) ...\n",
            "Setting up python-bs4 (4.6.0-1) ...\n",
            "Setting up python-lxml:amd64 (4.2.1-1ubuntu0.1) ...\n",
            "Setting up python-olefile (0.45.1-1) ...\n",
            "Setting up python-pil:amd64 (5.1.0-1) ...\n",
            "Setting up python-webencodings (0.5-2) ...\n",
            "Setting up python-chardet (3.0.4-1) ...\n",
            "Setting up python-html5lib (0.999999999-1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/content/models/research\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "Running tests under Python 3.6.9: /usr/bin/python3\n",
            "[ RUN      ] ModelBuilderTest.test_create_experimental_model\n",
            "[       OK ] ModelBuilderTest.test_create_experimental_model\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_model_from_config_with_example_miner\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[       OK ] ModelBuilderTest.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
            "[ RUN      ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_rfcn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_fpn_model_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[       OK ] ModelBuilderTest.test_create_ssd_models_from_config\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[       OK ] ModelBuilderTest.test_invalid_faster_rcnn_batchnorm_update\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[       OK ] ModelBuilderTest.test_invalid_first_stage_nms_iou_threshold\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[       OK ] ModelBuilderTest.test_invalid_model_config_proto\n",
            "[ RUN      ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[       OK ] ModelBuilderTest.test_invalid_second_stage_batch_size\n",
            "[ RUN      ] ModelBuilderTest.test_session\n",
            "[  SKIPPED ] ModelBuilderTest.test_session\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_faster_rcnn_feature_extractor\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[       OK ] ModelBuilderTest.test_unknown_meta_architecture\n",
            "[ RUN      ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "[       OK ] ModelBuilderTest.test_unknown_ssd_feature_extractor\n",
            "----------------------------------------------------------------------\n",
            "Ran 17 tests in 0.203s\n",
            "\n",
            "OK (skipped=1)\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5h9RbyaYC-b",
        "colab_type": "code",
        "outputId": "b64c99f7-fc64-4aa1-dc78-030f10180288",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from datetime import datetime\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from keras import applications, optimizers, backend as K\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Reshape, Conv2D, Activation\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, Callback, LambdaCallback\n",
        "from keras.utils import np_utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import io\n",
        "import sys\n",
        "import csv, json, pickle\n",
        "from lxml import etree\n",
        "\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/')\n",
        "from SecondStage_colab import second_stage_utils\n",
        "from SecondStage_colab import file_utils\n",
        "\n",
        "sys.path.append('/content/gdrive/My Drive/SecondStage_colab/')\n",
        "os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/SecondStage_colab/'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqzYclgV64T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#NAME =\n",
        "#example: cat_exptype_dataset(training)_dataset(eval)_conf(batch size etc) \n",
        "\n",
        "LOG_PATH = '/content/gdrive/My Drive/SecondStage_colab/output/'\n",
        "LABEL_MAP_PATH = '/content/gdrive/My Drive/SecondStage_colab/label_map.pbtxt'\n",
        "TRAIN_RECORD = '/content/gdrive/My Drive/data/generated/SecondStage_X/training_rot9_13colors.record'\n",
        "EVAL_RECORD = '/content/gdrive/My Drive/data/generated/SecondStage_X/validation_rot3_13colors.record'\n",
        "\n",
        "GPU = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG9YYdriX8WZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from file_utils import save_json\n",
        "from second_stage_utils import *\n",
        "\n",
        "def train(train_record, conf, out, rep=1):\n",
        "    timestamp = \"{:%Y-%m-%d-%H-%M}\".format(datetime.now())\n",
        "    log_path = LOG_PATH + conf['name'] + '_' + out + '/' + timestamp + '-r' + str(rep) + '/'\n",
        "    os.makedirs(log_path, exist_ok=True)\n",
        "    save_json(log_path + '/experiment_config.json', conf)\n",
        "\n",
        "    label_map = label_map_util.create_category_index_from_labelmap(LABEL_MAP_PATH)\n",
        "\n",
        "    num_classes = label_map_util.get_max_label_map_index(label_map_util.load_labelmap(LABEL_MAP_PATH)) + 1\n",
        "\n",
        "    X,Y,Z,_ = tf_record_load_crops([train_record])\n",
        "\n",
        "    X_train, Y_train, Z_train = data_to_keras(X,Y,Z,num_classes,conf['img_size'])\n",
        "    Z2_train = angle_to_bin(Z_train)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "    print(Y_train.shape)\n",
        "    print(num_classes)\n",
        "    print(Z2_train.shape)\n",
        "    print(NUM_ORI_BINS)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "\n",
        "    eval_records = EVAL_RECORD\n",
        "\n",
        "    X,Y,Z,_ = tf_record_extract_crops([eval_records], 1, 0.0, 0.0)\n",
        "    X_val, Y_val, Z_val = data_to_keras(X,Y,Z,num_classes,conf['img_size'])\n",
        "    Z2_val = angle_to_bin(Z_val)\n",
        "\n",
        "    assert len(X_val) > 0 and len(Y_val) > 0 and len(Z_val) > 0, '{} is incomplete'.format(eval_records)\n",
        "\n",
        "    outputs = None\n",
        "    model_final = None\n",
        "    summary = TensorBoardCustom(log_dir=log_path, label_map=label_map, AddCustomMetrics=(out == '_cat'))\n",
        "\n",
        "    filepath=log_path+\"model-{epoch:02d}.h5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, verbose=1, period=20)\n",
        "    if conf['optimizer'] == 'rmsprop':\n",
        "        optimizer = optimizers.RMSprop(lr=conf['learning_rate'])\n",
        "    elif conf['optimizer'] == 'adam':\n",
        "        optimizer = optimizers.Adam(lr=conf['learning_rate'])\n",
        "    else:\n",
        "        raise Error('Unknown optimizer: ' + conf['optimizer'])\n",
        "\n",
        "\n",
        "    mobilenet_base = applications.mobilenet.MobileNet(alpha = conf['alpha'],\n",
        "                                                      weights = \"imagenet\",\n",
        "                                                      include_top=False,\n",
        "                                                      dropout = conf['dropout'],\n",
        "                                                      input_shape = (\n",
        "                                                      conf['img_size'],\n",
        "                                                      conf['img_size'],\n",
        "                                                        3\n",
        "                                                      ))\n",
        "    shape = (1, 1, int(1024 * conf['alpha']))\n",
        "    x = GlobalAveragePooling2D()(mobilenet_base.output)\n",
        "    x = Reshape(shape, name='reshape_1')(x)\n",
        "    #x = Dropout(conf['dropout'], name='dropout')(x)\n",
        "\n",
        "    if out == '_cat':\n",
        "      # Branch classification\n",
        "      cat = Conv2D(num_classes, (1, 1),\n",
        "                padding='same', name='conv_cat')(x)\n",
        "      cat = Activation('softmax', name='act_softmax')(cat)\n",
        "      cat = Reshape((num_classes,), name='cat_out')(cat)\n",
        "      outputs = cat\n",
        "      model_final = Model(inputs = mobilenet_base.input, outputs = outputs)\n",
        "      model_final.compile(optimizer = optimizer,\n",
        "                          loss={'cat_out': 'categorical_crossentropy'},\n",
        "                          metrics ={'cat_out': 'accuracy'})\n",
        "      model_final.fit(\n",
        "        X_train,\n",
        "        {'cat_out': Y_train},\n",
        "        validation_data=(X_val, Y_val),\n",
        "        batch_size=conf['batch_size'], epochs = conf['epochs_cat'], verbose=1,\n",
        "        callbacks=[summary,checkpoint],\n",
        "        shuffle=True\n",
        "      )\n",
        "      \n",
        "    elif out == '_reg':\n",
        "      # Branch regression\n",
        "      reg = Conv2D(1, (1, 1),\n",
        "                padding='same', name='conv_reg')(x)\n",
        "      reg = Activation('linear', name='act_linear')(reg)\n",
        "      reg = Reshape((1,), name='reg_out')(reg)\n",
        "      outputs = reg\n",
        "      model_final = Model(inputs = mobilenet_base.input, outputs = outputs)\n",
        "      model_final.compile(optimizer = optimizer,\n",
        "                          loss={'reg_out': angle_mse},\n",
        "                          metrics ={'reg_out': angle_mae})\n",
        "      model_final.fit(\n",
        "        X_train,\n",
        "        {'reg_out': Z_train},\n",
        "        validation_data=(X_val, Z_val),\n",
        "        batch_size=conf['batch_size'], epochs = conf['epochs_reg'], verbose=1,\n",
        "        callbacks=[summary,checkpoint],\n",
        "        shuffle=True\n",
        "      )\n",
        "            \n",
        "    elif out == '_bin':\n",
        "      # Branch orientation classification with bins\n",
        "      bin = Conv2D(NUM_ORI_BINS, (1, 1),\n",
        "                padding='same', name='conv_bin')(x)\n",
        "      bin = Activation('softmax', name='act_bin')(bin)\n",
        "      bin = Reshape((NUM_ORI_BINS,), name='bin_out')(bin)\n",
        "      outputs = bin\n",
        "      model_final = Model(inputs = mobilenet_base.input, outputs = outputs)\n",
        "      model_final.compile(optimizer = optimizer,\n",
        "                          loss= {'bin_out': 'categorical_crossentropy'},\n",
        "                          metrics = [angle_bin_mae, angle_bin_rmse])\n",
        "      model_final.fit(\n",
        "        X_train,\n",
        "        {'bin_out': Z2_train},\n",
        "        validation_data=(X_val, Z2_val),\n",
        "        batch_size=conf['batch_size'], epochs = conf['epochs_bin'], verbose=1,\n",
        "        callbacks=[summary,checkpoint],\n",
        "        shuffle=True\n",
        "      )\n",
        "    else:\n",
        "        print('UNKNOWN OUTPUT CONFIG {}'.format(out))\n",
        "\n",
        "    model_final.save(log_path+\"model-final.h5\")\n",
        "    print(log_path)\n",
        "    print(\"Finished training for {}\".format(conf['name']))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jru6gJiHAVl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "cb4e17c9-e6f0-440c-ddf7-740855c82541"
      },
      "source": [
        "default_sstage_conf = {\n",
        "    'dataset': 'default',\n",
        "    'epochs_cat': 40,\n",
        "    'epochs_reg': 40,\n",
        "    'epochs_bin': 40,\n",
        "    'optimizer': 'adam',\n",
        "    'learning_rate': 3e-4,\n",
        "    'dropout': 0.001,\n",
        "    'alpha': 0.5,\n",
        "    'img_size': 35,\n",
        "    'repetions': 1,\n",
        "    'batch_size': 7020,\n",
        "}\n",
        "\n",
        "def create_all_sstage_experiments():\n",
        "    configs = []\n",
        "    #configs.extend(create_sstage_default())\n",
        "    #configs.extend(create_sstage_dropouts())\n",
        "    #configs.extend(create_sstage_alphas())\n",
        "    #configs.extend(create_sstage_dropouts_alphas())\n",
        "    configs.extend(create_sstage_batch_sizes())\n",
        "    return configs\n",
        "\n",
        "def create_sstage_batch_sizes():\n",
        "    config = []\n",
        "    batchsizes = [10530, 7020, 3510, 2106, 1053]\n",
        "    for size in batchsizes:\n",
        "      modified = deepcopy(default_sstage_conf)\n",
        "      modified['name'] = \"sstage_default_bsize\" + str(size)\n",
        "      modified['batch_size'] = size\n",
        "      config.append(deepcopy(modified))\n",
        "    return config\n",
        "\n",
        "def create_sstage_dropouts_alphas():\n",
        "    config = []\n",
        "    dropouts = [0.001, 0.3, 0.4, 0.5, 0.6] #\n",
        "    alphas = [0.25] # 0.5, 0.75, 1.0\n",
        "    for drop in dropouts:\n",
        "      modified = deepcopy(default_sstage_conf)\n",
        "      modified['name'] = \"ssdef_drop\" + str(drop)\n",
        "      modified['dropout'] = drop\n",
        "      for alp in alphas:\n",
        "        modifiedB = deepcopy(modified)\n",
        "        modifiedB['name'] = modifiedB['name'] + \"_alpha\" + str(alp)\n",
        "        modifiedB['alpha'] = alp\n",
        "        config.append(deepcopy(modifiedB))\n",
        "    return config\n",
        "\n",
        "def create_sstage_dropouts():\n",
        "    config = []\n",
        "    dropouts = [0.25]\n",
        "    for drop in dropouts:\n",
        "      modified = deepcopy(default_sstage_conf)\n",
        "      modified['name'] = \"sstage_default_drop\" + str(drop)\n",
        "      modified['dropout'] = drop\n",
        "      config.append(deepcopy(modified))\n",
        "    return config\n",
        "\n",
        "def create_sstage_alphas():\n",
        "    config = []\n",
        "    alphas = [0.5, 0.75, 1.0]\n",
        "    for alp in alphas:\n",
        "      modified = deepcopy(default_sstage_conf)\n",
        "      modified['name'] = \"sstage_default_alpha\" + str(alp)\n",
        "      modified['alpha'] = alp\n",
        "      config.append(deepcopy(modified))\n",
        "    return config\n",
        "\n",
        "def create_sstage_default():\n",
        "    config = []\n",
        "    modified = deepcopy(default_sstage_conf)\n",
        "    modified['name'] = \"sstage_default\"\n",
        "    config.append(deepcopy(modified))\n",
        "    return config\n",
        "\n",
        "exp = create_all_sstage_experiments()\n",
        "TORUN = []\n",
        "TORUN.append('_bin')\n",
        "TORUN.append('_cat')\n",
        "train_records = [ 'training_rot9_13colors.record']\n",
        "for config in tqdm(exp):\n",
        "    print(\"or_conf\", config)\n",
        "    for r in range(config['repetions']):     \n",
        "        for out in TORUN: # \n",
        "            for train_record in train_records:\n",
        "              conf = deepcopy(config)\n",
        "              conf['name'] = conf['name']+'_'+out+\"_\"+train_record\n",
        "              print(\"Start training:  \" + conf['name'])\n",
        "              \n",
        "              if not GPU:\n",
        "                  p = Process(\n",
        "                    target=train,\n",
        "                    args=(\"/content/gdrive/My Drive/data/generated/SecondStage_X/\" + train_record, conf, out, r)\n",
        "                  )\n",
        "                  p.start() \n",
        "              else:\n",
        "                train(\"/content/gdrive/My Drive/data/generated/SecondStage_X/\" + train_record, conf, out)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/5 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "or_conf {'dataset': 'default', 'epochs_cat': 40, 'epochs_reg': 40, 'epochs_bin': 40, 'optimizer': 'adam', 'learning_rate': 0.0003, 'dropout': 0.001, 'alpha': 0.5, 'img_size': 35, 'repetions': 1, 'batch_size': 10530, 'name': 'sstage_default_bsize10530'}\n",
            "Start training:  sstage_default_bsize10530__bin_training_rot9_13colors.record\n",
            "WARNING:tensorflow:From /content/models/research/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/SecondStage_colab/second_stage_utils.py:80: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use eager execution and: \n",
            "`tf.data.TFRecordDataset(path)`\n",
            "Loaded 210600 crops from ['/content/gdrive/My Drive/data/generated/SecondStage_X/training_rot9_13colors.record']\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n",
            "(210600, 14)\n",
            "14\n",
            "(210600, 360)\n",
            "360\n",
            "´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2041: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras_applications/mobilenet.py:207: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  warnings.warn('`input_shape` is undefined or non-square, '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_5_0_224_tf_no_top.h5\n",
            "5578752/5577668 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 210600 samples, validate on 27000 samples\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/SecondStage_colab/second_stage_utils.py:191: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/gdrive/My Drive/SecondStage_colab/second_stage_utils.py:192: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/40\n",
            "210600/210600 [==============================] - 517s 2ms/step - loss: 6.8756 - angle_bin_mae: 87.3739 - angle_bin_rmse: 103.3843 - val_loss: 7.6321 - val_angle_bin_mae: 82.0873 - val_angle_bin_rmse: 101.9405\n",
            "Epoch 2/40\n",
            " 52650/210600 [======>.......................] - ETA: 6:11 - loss: 6.0234 - angle_bin_mae: 82.7929 - angle_bin_rmse: 102.3790"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nukOQRHZg0uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "# LOG_PATH did not work for some reason\n",
        "%tensorboard --logdir '/content/gdrive/My Drive/SecondStage_colab/output/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwb-Lucxg2Bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install -U tensorboard >piplog 2>&1\n",
        "#!tensorboard dev upload --logdir '/content/gdrive/My Drive/SecondStage_colab/output/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Gdp0D8g8CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorboard >piplog 2>&1\n",
        "!tensorboard dev list\n",
        "# You must replace YOUR_EXPERIMENT_ID with the value output from the previous\n",
        "# tensorboard `list` command or `upload` command.  For example\n",
        "# `tensorboard dev delete --experiment_id pQpJNh00RG2Lf1zOe9BrQA`\n",
        "\n",
        "## !tensorboard dev delete --experiment_id YOUR_EXPERIMENT_ID_HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L68U_e3kg3K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm \"/content/gdrive/My Drive/SecondStage_colab/output/\" -rf\n",
        "#!ls \"/content/gdrive/My Drive/SecondStage_colab/\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
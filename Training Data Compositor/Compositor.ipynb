{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Compositor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvDa1Ekp-0Gc",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "- der compositor benutzt alle crops im Pfad CROP_PATH um die trainingsdaten zu erstellen\n",
        "    - zusätzlich zu den unterpfaden 'training' und 'validation'\n",
        "- die crops müssen einen runden cut mit alpha channel besitzen (als PNG Datei)\n",
        "    => verhindert, dass das netz einfach die ränder der crops lernt\n",
        "- der Dateiname der crops muss so aussehen: YX.png\n",
        "    - Y = klasse aus 'sphero_classes' dictionary X=nummerierung für die crops\n",
        "    - z.B. bright_blue0.png, bright_blue1.png, ...\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGB9rUHw-xjQ",
        "colab_type": "code",
        "outputId": "749b9bf9-7485-476d-ebfd-b57fd372e473",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "\n",
        "import csv\n",
        "import datetime\n",
        "import decimal\n",
        "import copy\n",
        "import io\n",
        "from os import listdir, makedirs\n",
        "from os.path import isfile, join\n",
        "import random\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageEnhance\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "np.random.seed(146324)\n",
        "\n",
        "print(tf.__version__)\n",
        "\n",
        "object_classes = {\n",
        "    \"sphero\": 1\n",
        "}\n",
        "\n",
        "\n",
        "sphero_11_classes = {\n",
        "    \"red\": 1,\n",
        "    \"orange\": 2,\n",
        "    \"yellow\": 3,\n",
        "    \"lime_green\": 4,\n",
        "    \"magenta\": 5, \n",
        "    \"purple\": 6,\n",
        "    \"green\": 7,\n",
        "    \"light_green\": 8,\n",
        "    \"blue_green\": 9,\n",
        "    \"light_blue\": 10,\n",
        "    \"blue\": 11,\n",
        "}\n",
        "\n",
        "sphero_9_classes = {\n",
        "    \"red\": 1,\n",
        "    \"yellow\": 2,\n",
        "    \"lime_green\": 3,\n",
        "    \"magenta\": 4, \n",
        "    \"purple\": 5,\n",
        "    \"green\": 6,\n",
        "    \"blue_green\": 7,\n",
        "    \"light_blue\": 8,\n",
        "    \"blue\": 9,\n",
        "}\n",
        "\n",
        "sphero_classes = sphero_9_classes\n",
        "\n",
        "\n",
        "def int64_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
        "\n",
        "\n",
        "def int64_list_feature(value):\n",
        "  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n",
        "\n",
        "\n",
        "def bytes_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
        "\n",
        "\n",
        "def bytes_list_feature(value):\n",
        "  return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n",
        "\n",
        "\n",
        "def float_list_feature(value):\n",
        "  return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "- SHAPE = (height, width, 3)\n",
        "- the images have a random brightness\n",
        "\"\"\"\n",
        "def generate_gaussiannoiseimg(SHAPE = (1200, 1600, 3), brtn = None):\n",
        "    noise = np.random.randint(0, 255, SHAPE)\n",
        "    noise = noise.astype(dtype=np.uint8)\n",
        "    img = Image.fromarray(noise, mode='RGB')\n",
        "    img = ImageEnhance.Color(img).enhance(1.2)\n",
        "    img = ImageEnhance.Contrast(img).enhance(1.2)\n",
        "    # random brightness\n",
        "    if brtn is None:\n",
        "        brtn = np.random.uniform(0.1, 0.3)\n",
        "    img = ImageEnhance.Brightness(img).enhance(brtn)\n",
        "    return img\n",
        "\n",
        "\n",
        "def generate_random_image(img, bg, edge_distance=0, rot=None):\n",
        "    # random scale\n",
        "    img = copy.deepcopy(img)\n",
        "    bg = copy.deepcopy(bg)\n",
        "    scl = round(np.random.uniform(0.95, 1.05), 2)\n",
        "    img = img.resize((int(scl*img.width),int(scl*img.height)), resample=Image.LANCZOS)\n",
        "\n",
        "    # random rotation\n",
        "    if rot is None:\n",
        "        rot = np.random.randint(360)\n",
        "    img = img.rotate(rot, resample=Image.BICUBIC, expand=False)\n",
        "\n",
        "    # random brightness\n",
        "    brtn = round(np.random.uniform(0.9, 1.1), 2)\n",
        "    img = ImageEnhance.Brightness(img).enhance(brtn)\n",
        "\n",
        "    # random position\n",
        "    # !position is the upper left corner of the crop in the picture!\n",
        "    assert bg.width-img.width - edge_distance >= 0, \"Abstand zum Rand ist zu hoch eingestellt!\"\n",
        "    assert bg.height-img.height - edge_distance >= 0, \"Abstand zum Rand ist zu hoch eingestellt!\"\n",
        "    pos = (np.random.randint(edge_distance, bg.width-img.width-edge_distance), np.random.randint(edge_distance, bg.height-img.height-edge_distance))\n",
        "    bg.paste(img, pos, img)\n",
        "    return bg, img, pos, brtn, rot, scl\n",
        "\n",
        "\n",
        "def writecsv(filename, csv_rows):\n",
        "    with open(filename, 'w') as csvfile:\n",
        "        spamwriter = csv.writer(csvfile, delimiter=',',\n",
        "                                quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
        "        for row in csv_rows:\n",
        "            spamwriter.writerow(row)\n",
        "\n",
        "\n",
        "def writetfrecord(filename, tf_examples):\n",
        "    writer = tf.io.TFRecordWriter(filename)\n",
        "    for example in tf_examples:\n",
        "        writer.write(example.SerializeToString())\n",
        "    writer.close()\n",
        "\n",
        "#img = generate_gaussiannoiseimg(SHAPE = (500, 500, 3), brtn=1.0)\n",
        "#img.save(\"gaussian_noise.png\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KIpLZrCP_Pfj",
        "colab_type": "text"
      },
      "source": [
        "first stage: objection detection (to learn a bounding box for the objects)\n",
        "- random rgb noise backgrounds mit random brightness in Größe 300x300\n",
        "- auf die backgrounds werden die sphero crops superimposed\n",
        "- die crops haben eine random scale, rotation, brightness und position im background\n",
        "- object_class, object_class_str: Id der objektklasse mit dem namen (siehe 'object_classes')\n",
        "- xmin, xmax, ymin, ymax: sind die koordinaten der bounding box"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zwniwe7_L_2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def firststage(isTrainingData, saveImages=False):\n",
        "    TRAIN_SIZE = 5000\n",
        "    TEST_SIZE = 1500\n",
        "    BGHEIGHT = 300\n",
        "    BGWIDTH = 300\n",
        "    FOLDER = \"validation\"\n",
        "    SIZE = TEST_SIZE\n",
        "    if isTrainingData:\n",
        "        FOLDER = \"training\"\n",
        "        SIZE = TRAIN_SIZE\n",
        "    OUT_PATH = \"output/\"\n",
        "    CROP_PATH = \"crops_11_colors/\" + FOLDER + \"/\"\n",
        "    timestamp = \"{:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
        "    timestamp = \"X\"\n",
        "    IMG_OUT_PATH = OUT_PATH+\"FirstStage_\"+timestamp+\"/\"  + FOLDER + \"/\"\n",
        "    TFREC_OUT_PATH = OUT_PATH+\"FirstStage_\"+timestamp+\"/\" + FOLDER\n",
        "    makedirs(IMG_OUT_PATH, exist_ok=True)\n",
        "\n",
        "    CROPS = [f for f in listdir(CROP_PATH) if isfile(join(CROP_PATH, f))]\n",
        "    tf_examples = []\n",
        "    tfrec_writer = tf.io.TFRecordWriter(TFREC_OUT_PATH+\".record\")\n",
        "    for i in trange(SIZE):\n",
        "        bg = generate_gaussiannoiseimg(SHAPE = (BGHEIGHT, BGWIDTH, 3))\n",
        "        xmins, xmaxs, ymins, ymaxs, obj_class_str, obj_class = [], [], [], [], [], []\n",
        "        for k in range(random.randint(2,5)):\n",
        "            crop = np.random.choice(CROPS)\n",
        "            img = Image.open(CROP_PATH + crop, 'r')\n",
        "            if not isTrainingData:\n",
        "                img = img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "            # repeat as long as we have a sphero that overlaps on another sphero\n",
        "            repeat = True\n",
        "            while repeat:\n",
        "                new_bg, new_img, pos, _,_,_ = generate_random_image(img, bg, edge_distance=5)\n",
        "                addedsize = 5\n",
        "                xmin = pos[0] - addedsize\n",
        "                xmax = pos[0] + addedsize + img.width\n",
        "                ymin = pos[1] - addedsize\n",
        "                ymax = pos[1] + addedsize + img.height\n",
        "                repeat = False\n",
        "                for p in range(len(xmins)):\n",
        "                    # check if overlapping another sphero, bounding box style\n",
        "                    if ymin >= ymins[p] and ymin <= ymaxs[p] and xmin >= xmins[p] and xmin <= xmaxs[p]:\n",
        "                        repeat = True\n",
        "                    if ymin >= ymins[p] and ymin <= ymaxs[p] and xmax >= xmins[p] and xmax <= xmaxs[p]:\n",
        "                        repeat = True\n",
        "                    if ymax >= ymins[p] and ymax <= ymaxs[p] and xmin >= xmins[p] and xmin <= xmaxs[p]:\n",
        "                        repeat = True\n",
        "                    if ymax >= ymins[p] and ymax <= ymaxs[p] and xmax >= xmins[p] and xmax <= xmaxs[p]:\n",
        "                        repeat = True\n",
        "\n",
        "\n",
        "            img = new_img\n",
        "            bg = new_bg\n",
        "            xmins.append(xmin)\n",
        "            xmaxs.append(xmax)\n",
        "            ymins.append(ymin)\n",
        "            ymaxs.append(ymax)\n",
        "            obj_class_str.append(\"sphero\".encode('utf8'))\n",
        "            obj_class.append(object_classes.get(\"sphero\"))\n",
        "        xmins = [x / bg.width for x in xmins]\n",
        "        xmaxs = [x / bg.width for x in xmaxs]\n",
        "        ymins = [x / bg.height for x in ymins]\n",
        "        ymaxs = [x / bg.height for x in ymaxs]\n",
        "        image_name = str(i) +  \".png\"\n",
        "        with io.BytesIO() as output:\n",
        "            bg.save(output, format=\"PNG\")\n",
        "            io_image = output.getvalue()\n",
        "\n",
        "        tf_example = tf.train.Example(features=tf.train.Features(feature={      \n",
        "            'image/encoded': bytes_feature(io_image),\n",
        "            'image/format': bytes_feature(b'png'),\n",
        "            'image/filename': bytes_feature(image_name.encode('utf8')),\n",
        "            'image/source_id': bytes_feature(image_name.encode('utf8')),\n",
        "            'image/width': int64_feature(bg.width),\n",
        "            'image/height': int64_feature(bg.height),\n",
        "            'image/object/class/text': bytes_list_feature(obj_class_str),\n",
        "            'image/object/class/label': int64_list_feature(obj_class),\n",
        "            'image/object/bbox/xmin': float_list_feature(xmins),\n",
        "            'image/object/bbox/xmax': float_list_feature(xmaxs),\n",
        "            'image/object/bbox/ymin': float_list_feature(ymins),\n",
        "            'image/object/bbox/ymax': float_list_feature(ymaxs),\n",
        "        }))\n",
        "        tf_examples.append(tf_example)\n",
        "        if saveImages:\n",
        "            bg.save(IMG_OUT_PATH+image_name)\n",
        "        if i % 500:\n",
        "            # prevents the RAM from getting full\n",
        "            for example in tf_examples:\n",
        "                tfrec_writer.write(example.SerializeToString())\n",
        "            tf_examples = []\n",
        "\n",
        "    for example in tf_examples:\n",
        "        tfrec_writer.write(example.SerializeToString())\n",
        "    tfrec_writer.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85WLGFRE_6Ef",
        "colab_type": "text"
      },
      "source": [
        "second stage: Identification CNN and Orientation CNN\n",
        "=> Identification CNN: hohe vielfalt an farben, rotationen und helligkeiten\n",
        "=> Orientation CNN: hohe vielfalt an rotationen mit unterschiedlichen farben und helligkeiten\n",
        "\n",
        "- random rgb noise backgrounds mit random brightness in Größe 35x35\n",
        "- die crops haben die größe 25x25\n",
        "- jeder crop wird X mal mit jedem winkel erstellt\n",
        "- zusätzlich erhalten die crops eine random scale, random helligkeit und random position im background\n",
        "- die CSV datei enthält folgende spalten:\n",
        "- img_class, img_class_str: ID der klasse und der name der klasse (siehe 'sphero_classes' dict)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIA5oHFgANqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def secondstage(isTrainingData, saveImages=False, RotRepetitions=1):\n",
        "\n",
        "    BGHEIGHT = 35\n",
        "    BGWIDTH = 35\n",
        "    FOLDER = \"validation\"\n",
        "    if isTrainingData:\n",
        "        FOLDER = \"training\"\n",
        "    OUT_PATH = \"output/\"\n",
        "    CROP_PATH = \"crops_9_colors/\" + FOLDER + \"/\"\n",
        "    timestamp = \"{:%Y%m%d_%H%M%S}\".format(datetime.datetime.now())\n",
        "    timestamp = \"X\"\n",
        "    IMG_OUT_PATH = OUT_PATH+\"SecondStage_\"+timestamp+\"/\"  + FOLDER + \"/\"\n",
        "    TFREC_OUT_PATH = OUT_PATH+\"SecondStage_\"+timestamp+\"/\" + FOLDER\n",
        "    makedirs(IMG_OUT_PATH, exist_ok=True)\n",
        "    \n",
        "    CROPS = [f for f in listdir(CROP_PATH) if (isfile(join(CROP_PATH, f)) and f.endswith('.png'))]\n",
        "    csv_rows = []\n",
        "    tf_examples = []\n",
        "\n",
        "    for crop in tqdm(CROPS):\n",
        "        for rot in range(360):\n",
        "            for k in range(RotRepetitions):\n",
        "                img = Image.open(CROP_PATH + crop)\n",
        "                if not isTrainingData:\n",
        "                    img = img.transpose(PIL.Image.FLIP_LEFT_RIGHT)\n",
        "                bg = generate_gaussiannoiseimg(SHAPE = (BGHEIGHT, BGWIDTH, 3), brtn=0.2)\n",
        "\n",
        "                bg, img, pos, brtn, rot, scl = generate_random_image(img, bg, 3, rot)\n",
        "\n",
        "                # save image and csv\n",
        "                with io.BytesIO() as output:\n",
        "                    bg.save(output, format=\"PNG\")\n",
        "                    io_image = output.getvalue()\n",
        "                obj_class_str = \"sphero\"\n",
        "                obj_class = object_classes.get(obj_class_str)\n",
        "                img_class_str = crop[:-5]\n",
        "                img_class = sphero_classes.get(img_class_str)\n",
        "                image_name = img_class_str + crop[-5] + \"_r\" + str(rot) + \"_\" + str(k) + \".png\"\n",
        "                if saveImages:\n",
        "                    bg.save(IMG_OUT_PATH+image_name)\n",
        "                tf_example = tf.train.Example(features=tf.train.Features(feature={      \n",
        "                    'image/encoded': bytes_feature(io_image),\n",
        "                    'image/format': bytes_feature(b'png'),\n",
        "                    'image/filename': bytes_feature(image_name.encode('utf8')),\n",
        "                    'image/source_id': bytes_feature(image_name.encode('utf8')),\n",
        "                    'image/width': int64_feature(bg.width),\n",
        "                    'image/height': int64_feature(bg.height),\n",
        "                    'image/object/class/text': bytes_feature(obj_class_str.encode('utf8')),\n",
        "                    'image/object/class/label': int64_feature(obj_class),\n",
        "                    'image/object/subclass/text': bytes_feature(img_class_str.encode('utf8')),\n",
        "                    'image/object/subclass/label': int64_feature(img_class),\n",
        "                    'image/object/pose/orientation': int64_feature(rot),\n",
        "\n",
        "                }))\n",
        "                tf_examples.append(tf_example)\n",
        "\n",
        "    writetfrecord(TFREC_OUT_PATH+\"_rot\"+str(RotRepetitions)+\"_9colors.record\", tf_examples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL0Slr0hBvWA",
        "colab_type": "code",
        "outputId": "15607ec5-fb2a-480b-c8fa-0d8512dffbb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "os.chdir('/content/drive/My Drive/Colab Notebooks')\n",
        "# Upload the crops folder to the folder above\n",
        "# Should look like this:\n",
        "#   crops_11_colors/\n",
        "#   |------\\training\n",
        "#   |------\\validation\n",
        "#\n",
        "# the *.record files from the compositor are created in '/content/drive/My Drive/Colab Notebooks/output'\n",
        "# make sure you have enough space available in your google drive (at least ~2GB)\n",
        "# I would not recommend to save the individual image files created by the compositor to google drive\n",
        "# google drive might also take a while to display the 'output' folder in the google drive view"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHV__4F1ARPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#firststage(isTrainingData=True, saveImages=False)\n",
        "#firststage(isTrainingData=False, saveImages=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uR06-JkWAV8y",
        "colab_type": "code",
        "outputId": "95bf31a4-1f2d-4846-b02b-5c1c19087eb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#secondstage(isTrainingData=True, saveImages=False, RotRepetitions=1)\n",
        "#secondstage(isTrainingData=True, saveImages=False, RotRepetitions=3)\n",
        "#secondstage(isTrainingData=True, saveImages=False, RotRepetitions=6)\n",
        "secondstage(isTrainingData=True, saveImages=False, RotRepetitions=9)\n",
        "#secondstage(isTrainingData=True, saveImages=False, RotRepetitions=12)\n",
        "#secondstage(isTrainingData=True, saveImages=False, RotRepetitions=15)\n",
        "secondstage(isTrainingData=False, saveImages=False, RotRepetitions=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 45/45 [05:20<00:00,  7.20s/it]\n",
            "100%|██████████| 18/18 [00:33<00:00,  1.78s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkG7ifF3Fhzw",
        "colab_type": "code",
        "outputId": "fb6e8016-f5be-41ff-df86-f729b1b88e2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "!ls\n",
        "# delete the complete output folder\n",
        "#!rm output -rf"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " AIDungeon_2_Uncensored.ipynb\t\t\t Exercise9_Dataanalysis.ipynb\n",
            " cifar_attempts.zip\t\t\t\t fail1.py\n",
            " Compositor2.ipynb\t\t\t\t fail2.py\n",
            " Compositor.ipynb\t\t\t\t fail3.py\n",
            "'Copy of Getting Started with TensorBoard.dev'\t fail4.py\n",
            " crops_11_colors\t\t\t\t fail5.py\n",
            " crops_9_colors\t\t\t\t\t idl_ex1.ipynb\n",
            " datasets.py\t\t\t\t\t idl_ex2_fails.ipynb\n",
            " Exercise10_CIFAR10.ipynb\t\t\t idl_ex2.ipynb\n",
            "'Exercise4 (1).ipynb'\t\t\t\t output\n",
            "'Exercise4 (2).ipynb'\t\t\t\t __pycache__\n",
            "'Exercise4 (3).ipynb'\t\t\t\t rnn_lowlevel.ipynb\n",
            "'Exercise4 (4).ipynb'\t\t\t\t SecondStage2.ipynb\n",
            "'Exercise4 (5).ipynb'\t\t\t\t Untitled\n",
            "'Exercise4 (6).ipynb'\t\t\t\t Untitled0.ipynb\n",
            "'Exercise4 (7).ipynb'\t\t\t\t'Untitled (1)'\n",
            " Exercise4.ipynb\t\t\t\t Untitled1.ipynb\n",
            " Exercise8_Autoencoders.ipynb\t\t\t Untitled2.ipynb\n",
            " Exercise9_CIFAR10.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
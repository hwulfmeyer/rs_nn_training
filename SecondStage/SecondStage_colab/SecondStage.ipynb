{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondStage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJlG_lwKEaQv",
        "colab_type": "text"
      },
      "source": [
        "to do:\n",
        "- image in tensorboard (test alpha mobilenet)\n",
        "- imports aufräumen\n",
        "- Secondstage.py\n",
        "- Konfiguration außerhalb:\n",
        "    - Name output\n",
        "    - cat/ bin/ reg\n",
        "- endliche Anzahl an Runden"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BcJ4A6G0rjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "#!pip install tensorflow-gpu==1.15\n",
        "!pip install object-detection-core\n",
        "from object_detection.utils import dataset_util\n",
        "from object_detection.utils import label_map_util\n",
        "from google.colab import drive, files\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5h9RbyaYC-b",
        "colab_type": "code",
        "outputId": "4db6813c-d82e-4d5e-d61e-beea4743e3e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "from datetime import datetime\n",
        "from multiprocessing import Process, Queue\n",
        "\n",
        "from copy import deepcopy\n",
        "\n",
        "from keras import applications, optimizers, backend as K\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D, Reshape, Conv2D, Activation, BatchNormalization, MaxPool2D, Input, GaussianNoise\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, Callback, LambdaCallback\n",
        "from keras.utils import np_utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy.random import randint\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import io\n",
        "import os\n",
        "import sys\n",
        "import csv, json, pickle\n",
        "from lxml import etree\n",
        "\n",
        "\n",
        "os.chdir('/content/gdrive/My Drive/')\n",
        "from SecondStage_colab import second_stage_utils\n",
        "from SecondStage_colab import file_utils\n",
        "\n",
        "sys.path.append('/content/gdrive/My Drive/SecondStage_colab/')\n",
        "os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/SecondStage_colab/'\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqzYclgV64T0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LOG_PATH = '/content/gdrive/My Drive/SecondStage_colab/output/'\n",
        "LABEL_MAP_PATH = '/content/gdrive/My Drive/SecondStage_colab/robot_label_map_komplett.pbtxt'\n",
        "RECORD_PATH = '/content/gdrive/My Drive/data/generated/SecondStage_X/'\n",
        "\n",
        "GPU = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG9YYdriX8WZ",
        "colab_type": "code",
        "outputId": "4cc069ba-d1bd-411c-cc42-84c0922b527f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from file_utils import save_json\n",
        "from second_stage_utils import *\n",
        "\n",
        "# you can not set these here, change them in the second_stage_utils\n",
        "print(ANGLES_PER_BIN)\n",
        "print(NUM_ORI_BINS)\n",
        "\n",
        "\n",
        "def train(train_record, eval_record, conf, out, rep=1, useMobileNet=True):\n",
        "    timestamp = \"{:%Y-%m-%d-%H-%M}\".format(datetime.now())\n",
        "    log_path = LOG_PATH + conf['name'] + '_' + out + '/' + timestamp + '-r' + str(rep) + '/'\n",
        "    os.makedirs(log_path, exist_ok=True)\n",
        "    save_json(log_path + '/experiment_config.json', conf)\n",
        "\n",
        "    label_map = label_map_util.create_category_index_from_labelmap(LABEL_MAP_PATH)\n",
        "    num_classes = label_map_util.get_max_label_map_index(label_map_util.load_labelmap(LABEL_MAP_PATH)) + 1\n",
        "    \n",
        "    X,Y,Z,_ = tf_record_load_crops([train_record])\n",
        "    print(\"--- crops loaded ---\")\n",
        "    num_classes = label_map_util.get_max_label_map_index(label_map_util.load_labelmap(LABEL_MAP_PATH)) + 1\n",
        "    X_train, Y_train, Z_train = data_to_keras(X,Y,Z, num_classes, conf['img_size'])\n",
        "    Z2_train = angle_to_bin(Z_train)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "    print(Y_train.shape)\n",
        "    print(num_classes)\n",
        "    print(Z2_train.shape)\n",
        "    print(NUM_ORI_BINS)\n",
        "    print(\"´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´´\")\n",
        "\n",
        "    X,Y,Z,_ = tf_record_extract_crops([eval_record], 1, 0.0, 0.0)\n",
        "    X_val, Y_val, Z_val = data_to_keras(X,Y,Z,num_classes,conf['img_size'])\n",
        "    Z2_val = angle_to_bin(Z_val)\n",
        "\n",
        "    assert len(X_val) > 0 and len(Y_val) > 0 and len(Z_val) > 0, '{} is incomplete'.format(eval_record)\n",
        "\n",
        "    outputs = None\n",
        "    model_final = None\n",
        "    # add the tensorboardcustom, the tensorboard custom includes the confusion matrix\n",
        "    # 'AddCustomMetrics' controls the ConfusioMatrix, Precision, Recall, F1\n",
        "    summary = TensorBoardCustom(log_dir=log_path, label_map=label_map, AddCustomMetrics=(out == '_cat'))\n",
        "    # early stopping, patience is the number of epochs to wait\n",
        "    earlyStop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    filepath=log_path+\"model-{epoch:02d}.h5\"\n",
        "    checkpoint = ModelCheckpoint(filepath, verbose=1, period=20)\n",
        "    if conf['optimizer'] == 'rmsprop':\n",
        "        optimizer = optimizers.RMSprop(lr=conf['learning_rate'])\n",
        "    elif conf['optimizer'] == 'adam':\n",
        "        optimizer = optimizers.Adam(lr=conf['learning_rate'])\n",
        "    else:\n",
        "        raise Error('Unknown optimizer: ' + conf['optimizer'])\n",
        "\n",
        "    loss_weights = [1.0 if out == '_cat' else 0.0, 1.0 if out == '_reg' else 0.0, 1.0 if out == '_bin' else 0.0]\n",
        "    epochs = 0\n",
        "    if out == '_cat': \n",
        "      epochs = conf['epochs_cat']\n",
        "    elif out == '_reg': \n",
        "      epochs = conf['epochs_reg']\n",
        "    else:\n",
        "      epochs = conf['epochs_bin']\n",
        "    model_final = None\n",
        "    if useMobileNet:\n",
        "      mobilenet_base = applications.mobilenet.MobileNet(alpha = conf['alpha'],\n",
        "                                                        weights = \"imagenet\",\n",
        "                                                        include_top=False,\n",
        "                                                        dropout = conf['dropout'],\n",
        "                                                        input_shape = (\n",
        "                                                        conf['img_size'],\n",
        "                                                        conf['img_size'],\n",
        "                                                          3\n",
        "                                                        ))\n",
        "      \n",
        "      x = GlobalAveragePooling2D()(mobilenet_base.output)\n",
        "      x = Dense(128, activation='relu')(x)\n",
        "      # Branch regression\n",
        "      reg = Dense(1, activation='linear', name='dense_reg')(x)\n",
        "      reg = Reshape((1,), name='reg_out')(reg)\n",
        "      # Branch orientation classification with bins\n",
        "      bin = Dense(NUM_ORI_BINS, activation='softmax', name='dense_bin')(x)\n",
        "      bin = Reshape((NUM_ORI_BINS,), name='bin_out')(bin)\n",
        "      # Branch classification\n",
        "      cat = GaussianNoise(stddev=0.2)(x)\n",
        "      cat = Conv2D(num_classes, (1, 1), padding='same', name='conv_cat')(x) \n",
        "      cat = GaussianNoise(stddev=0.01)(cat)\n",
        "      cat = Dense(num_classes, activation='softmax', name='dense_cat')(x)\n",
        "      cat = Reshape((num_classes,), name='cat_out')(cat)\n",
        "\n",
        "      model_final = Model(inputs = mobilenet_base.input, outputs = [cat,reg,bin])\n",
        "\n",
        "    else:\n",
        "      inputs = Input(shape=(35,35,3), name = 'input_1')\n",
        "      x = GaussianNoise(3.0)(inputs)\n",
        "      x = Conv2D(32, (3,3), padding='same', activation='relu', input_shape=(35, 35, 3))(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = MaxPool2D()(x)\n",
        "      x = Conv2D(64, (3,3), padding='same', activation='relu')(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = MaxPool2D()(x)\n",
        "      filters = 128\n",
        "      x = Conv2D(filters, (3,3), padding='same', activation='relu')(x)\n",
        "      x = BatchNormalization()(x)\n",
        "      x = MaxPool2D()(x)\n",
        "      x = Reshape((filters*16,))(x)\n",
        "      #x = Flatten()(x)\n",
        "      x = Dropout(conf['dropout'])(x)\n",
        "      x = Dense(512, activation='relu')(x)\n",
        "      x = Dropout(conf['dropout'])(x)\n",
        "      x = Dense(512, activation='relu')(x)\n",
        "      # Branch regression\n",
        "      reg = Dense(1, activation='linear', name='dense_reg')(x)\n",
        "      reg = Reshape((1,), name='reg_out')(reg)\n",
        "      # Branch orientation classification with bins\n",
        "      bin = Dense(NUM_ORI_BINS, activation='softmax', name='dense_bin')(x)\n",
        "      bin = Reshape((NUM_ORI_BINS,), name='bin_out')(bin)\n",
        "      # Branch classification\n",
        "      cat = Dense(num_classes, activation='softmax', name='dense_cat')(x)\n",
        "      cat = Reshape((num_classes,), name='cat_out')(cat)\n",
        "\n",
        "      model_final = Model(inputs = inputs, outputs = [cat,reg,bin])\n",
        "\n",
        "    model_final.compile(optimizer = optimizer,\n",
        "                  loss={'cat_out': 'categorical_crossentropy',\n",
        "                        'reg_out': angle_mse,\n",
        "                        'bin_out': 'categorical_crossentropy',\n",
        "                  },\n",
        "                  loss_weights={'cat_out': loss_weights[0],\n",
        "                                'reg_out': loss_weights[1],\n",
        "                                'bin_out': loss_weights[2]},\n",
        "                  metrics ={'cat_out': 'accuracy',\n",
        "                            'reg_out': angle_mae,\n",
        "                            'bin_out': angle_bin_rmse})\n",
        "    orig_stdout = sys.stdout\n",
        "    with open(log_path + 'model_summary.txt', 'w') as f:\n",
        "      sys.stdout = f \n",
        "      print(model_final.summary())\n",
        "      f.close()\n",
        "    sys.stdout = orig_stdout\n",
        "\n",
        "    model_final.fit(\n",
        "        X_train,\n",
        "        {'cat_out': Y_train, 'reg_out': Z_train, 'bin_out': Z2_train},\n",
        "        validation_data=(X_val, [Y_val, Z_val, Z2_val]),\n",
        "        batch_size=conf['batch_size'], epochs=epochs, verbose=1,\n",
        "        callbacks=[summary, checkpoint, earlyStop],\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    model_final.save(log_path+\"model-final.h5\")\n",
        "    print(log_path)\n",
        "    print(\"Finished training for {}\".format(conf['name']))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "360\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Jru6gJiHAVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "default_sstage_conf = {\n",
        "    'dataset': 'default',\n",
        "    'epochs_cat': 70,\n",
        "    'epochs_reg': 70,\n",
        "    'epochs_bin': 70,\n",
        "    'optimizer': 'adam',\n",
        "    'learning_rate': 1e-3,\n",
        "    'dropout': 0.001,\n",
        "    'alpha': 0.5,\n",
        "    'img_size': 35,\n",
        "    'repetions': 3,\n",
        "    'batch_size': 4096*2,\n",
        "}\n",
        "\n",
        "def create_all_sstage_experiments():\n",
        "    configs = []\n",
        "    #configs.extend(create_sstage_default())\n",
        "    configs.extend(create_sstage_dropouts())\n",
        "    #configs.extend(create_sstage_alphas())\n",
        "    return configs\n",
        "\n",
        "def create_sstage_alphas():\n",
        "    config = []\n",
        "    dropouts = [0.5]\n",
        "    for drop in dropouts:\n",
        "      modified = deepcopy(default_sstage_conf)\n",
        "      modified['name'] = \"ssdef_alpha\" + str(drop)\n",
        "      modified['dropout'] = drop\n",
        "      config.append(modified)\n",
        "    return config\n",
        "\n",
        "def create_sstage_dropouts():\n",
        "    config = []\n",
        "    dropouts = [0.5, 0.6]\n",
        "    for drop in dropouts:\n",
        "      modified = deepcopy(default_sstage_conf)\n",
        "      modified['name'] = \"ssdef_drop\" + str(drop)\n",
        "      modified['dropout'] = drop\n",
        "      config.append(modified)\n",
        "    return config\n",
        "\n",
        "def create_sstage_default():\n",
        "    config = []\n",
        "    modified = deepcopy(default_sstage_conf)\n",
        "    modified['name'] = \"ssdef\" + \"_\"\n",
        "    config.append(deepcopy(modified))\n",
        "    return config\n",
        "\n",
        "\n",
        "exp = create_all_sstage_experiments()\n",
        "TORUN = []\n",
        "#TORUN.append('_bin')\n",
        "TORUN.append('_cat')\n",
        "#TORUN.append('_reg')\n",
        "useMobileNet = False\n",
        "#RECORDS = [('training_rot9_13colors_neu_noflip.record', 'validation_rot6_13colors_neu.record')]\n",
        "#RECORDS = [('training_rot12_10colors.record','validation_rot12_10colors.record')]\n",
        "#RECORDS = [('training_rot12_13colors.record','validation_rot12_13colors.record')]\n",
        "#RECORDS = [('training_test.record', 'training_test.record')]\n",
        "\n",
        "for out in TORUN:\n",
        "  for config in tqdm(exp):\n",
        "    print(\"or_conf\", config)\n",
        "    for train_record, eval_records in RECORDS:\n",
        "      for r in range(config['repetions']):\n",
        "        conf = deepcopy(config)\n",
        "        conf['name'] = conf['name']+'_'+out+\"_\"+train_record\n",
        "        print(\"Start training:  \" + conf['name'])\n",
        "        \n",
        "        if not GPU:\n",
        "            p = Process(\n",
        "              target=train,\n",
        "              args=(RECORD_PATH + train_record, RECORD_PATH + eval_records, conf, out, r, useMobileNet)\n",
        "            )\n",
        "            p.start()\n",
        "        else:\n",
        "          train(RECORD_PATH + train_record, RECORD_PATH + eval_records, conf, out, useMobileNet)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nukOQRHZg0uB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#%load_ext tensorboard\n",
        "%reload_ext tensorboard\n",
        "# LOG_PATH did not work for some reason\n",
        "%tensorboard --logdir '/content/gdrive/My Drive/SecondStage_colab/output/' --samples_per_plugin images=0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwb-Lucxg2Bo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorboard >piplog 2>&1\n",
        "!tensorboard dev upload --logdir '/content/gdrive/My Drive/SecondStage_colab/output/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6Gdp0D8g8CP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U tensorboard >piplog 2>&1\n",
        "!tensorboard dev list\n",
        "# You must replace YOUR_EXPERIMENT_ID with the value output from the previous\n",
        "# tensorboard `list` command or `upload` command.  For example\n",
        "# `tensorboard dev delete --experiment_id pQpJNh00RG2Lf1zOe9BrQA`\n",
        "\n",
        "## !tensorboard dev delete --experiment_id YOUR_EXPERIMENT_ID_HERE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L68U_e3kg3K5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!rm \"/content/gdrive/My Drive/SecondStage_colab/output/\" -rf\n",
        "#!ls \"/content/gdrive/My Drive/SecondStage_colab/\"\n",
        "\"\"\"\n",
        "function ClickConnect(){\n",
        "console.log(\"Working\");\n",
        "document.querySelector(\"colab-connect-button\").shadowRoot.getElementById('connect').click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
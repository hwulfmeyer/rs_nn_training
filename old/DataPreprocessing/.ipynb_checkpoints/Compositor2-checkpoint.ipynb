{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#Fix problem with ros python path\n",
    "sys.path.remove('/opt/ros/kinetic/lib/python2.7/site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime, csv\n",
    "from enum import Enum\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from object_detection.utils import label_map_util\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import dataset_util\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "from CNNRobotLocalisation.Utils.file_utils import *\n",
    "from compositor import *\n",
    "from experiment_definitions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUT_PATH = \"/media/data/LocalizationDataNew/Output/Compositor2/\"\n",
    "PATH_TO_LABELS = \"/media/data/Dokumente/Nextcloud/Studium/Bachelorarbeit/CNNRobotLocalisation/LabelMaps/robot_label_map.pbtxt\"\n",
    "OBJECT_TAR_PATH = \"/media/data/LocalizationDataNew/CompositorInputData/RobotCrops/TrainData1\"\n",
    "BACKGROUND_TAR_PATH = \"/media/data/LocalizationDataNew/CompositorInputData/Backgrounds\"\n",
    "OBJECT_PATH = '/tmp/LocalizationData/RobotCrops'\n",
    "BACKGROUND_PATH = '/tmp/LocalizationData/Backgrounds'\n",
    "labelMapDict = label_map_util.get_label_map_dict(PATH_TO_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Untar to tmp dir\n",
    "\n",
    "assert 'tmp' in BACKGROUND_PATH\n",
    "assert 'tmp' in OBJECT_PATH\n",
    "shutil.rmtree(BACKGROUND_PATH,ignore_errors=True)\n",
    "shutil.rmtree(OBJECT_PATH,ignore_errors=True)\n",
    "for f in tqdm(get_recursive_file_list(OBJECT_TAR_PATH)):\n",
    "    with tarfile.open(f) as tar:\n",
    "        tar.extractall(f.replace(OBJECT_TAR_PATH,OBJECT_PATH).rsplit('/',1)[0])\n",
    "for f in tqdm(get_recursive_file_list(BACKGROUND_TAR_PATH,file_excludes=[\"COCO2.tar\"])):\n",
    "    with tarfile.open(f) as tar:\n",
    "        tar.extractall(f.replace(BACKGROUND_TAR_PATH,BACKGROUND_PATH).rsplit('/',1)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Stage Compositor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%autoreload\n",
    "\n",
    "timestamp = \"{:%Y-%m-%d-%H-%M-%S}\".format(datetime.datetime.now())\n",
    "\n",
    "compositor_settings, filters = create_background_diversity_experiment()\n",
    "for filt in filters:\n",
    "    set_name = filt['name']\n",
    "    typeObjectList = generate_balanced_object_list(OBJECT_PATH,filt)\n",
    "    backgroundFileList = generate_balanced_background_list(BACKGROUND_PATH,filt)\n",
    "    tf_examples = []\n",
    "    IMG_OUT_PATH = OUT_PATH+set_name+'-imgs/'\n",
    "    os.makedirs(IMG_OUT_PATH, exist_ok=True)\n",
    "\n",
    "    # about 3 min for 1000 images\n",
    "    for i in tqdm(range(compositor_settings['amount_images'])):\n",
    "        tf_example = composite(set_name,i,\n",
    "                               backgroundFileList,\n",
    "                               typeObjectList,\n",
    "                               compositor_settings,\n",
    "                               labelMapDict,\n",
    "                               IMG_OUT_PATH)\n",
    "        tf_examples.append(tf_example)\n",
    "\n",
    "    writer = tf.python_io.TFRecordWriter(OUT_PATH+set_name+\".record\")\n",
    "    for example in tf_examples:\n",
    "        writer.write(example.SerializeToString())\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second stage compositor\n",
    "\n",
    "**TODO: ignore undefined category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# TODO: Read images from stage 1 TFRecords\n",
    "\n",
    "timestamp = \"{:%Y-%m-%d-%H-%M-%S}\".format(datetime.datetime.now());\n",
    "#timestamp = 'test'\n",
    "csv_rows = []\n",
    "IMG_OUT_PATH = OUT_PATH+\"SecondStage/\"+timestamp+'-imgs/'\n",
    "os.makedirs(IMG_OUT_PATH, exist_ok=True)\n",
    "\n",
    "for i in tqdm(range(10000)):\n",
    "    bg_file = nr.choice(backgroundFileList)\n",
    "    bg = Image.open(bg_file).convert('RGB')\n",
    "    bg = bg.resize((OUT_SIZE_W, OUT_SIZE_H), resample=PIL.Image.LANCZOS)\n",
    "       \n",
    "    for j in range(3):\n",
    "        obj_meta = nr.choice(typeObjectList[0])\n",
    "        obj_type = obj_meta[\"robot_type\"]\n",
    "        obj = Image.open(obj_meta['crop'])\n",
    "\n",
    "        # random rotation\n",
    "        rot = nr.randint(360)\n",
    "        obj = obj.rotate(rot, resample=Image.BICUBIC, expand=True)\n",
    "        obj=obj.crop(obj.getbbox())\n",
    "        \n",
    "        # color transformation\n",
    "        brightness = nr.uniform(1.0,1.4)\n",
    "        enhancer = ImageEnhance.Brightness(obj)\n",
    "        obj = enhancer.enhance(brightness)\n",
    "\n",
    "        # random translation\n",
    "        pos = (nr.randint(0, bg.width-obj.width), nr.randint(0, bg.height-obj.height))\n",
    "        \n",
    "        imprecision = 0.15\n",
    "        offset = 0.05\n",
    "        x_imp = nr.randint(-imprecision*obj.width,+imprecision*obj.width) + int(offset*obj.width)\n",
    "        y_imp = nr.randint(-imprecision*obj.height,+imprecision*obj.height) + int(offset*obj.height)\n",
    "        w_imp = nr.randint(-imprecision*obj.width,+imprecision*obj.width) + int(offset*obj.width)\n",
    "        h_imp = nr.randint(-imprecision*obj.height,+imprecision*obj.height) + int(offset*obj.height)\n",
    "\n",
    "        bg.paste(obj, pos, obj.split()[-1])\n",
    "        roi = bg.crop((pos[0]-x_imp, pos[1]-y_imp, pos[0]+obj.width+w_imp, pos[1]+obj.height+h_imp))\n",
    "        roiname = timestamp + \"-img\"+str(i)+\"-obj\"+str(j)+\".png\"\n",
    "        roi.save(IMG_OUT_PATH+roiname)\n",
    "               \n",
    "        subclass = obj_meta['robot_type'] + '_' + obj_meta['identification']\n",
    "        subclass_text = (str.encode(subclass))\n",
    "        subclass = (labelMapDict[subclass])\n",
    "        csv_rows.append([roiname,subclass_text,subclass,rot])\n",
    "\n",
    "with open(IMG_OUT_PATH+\"0groundtruth.csv\", 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row in csv_rows:\n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(IMG_OUT_PATH+\"0groundtruth.csv\", 'w') as csvfile:\n",
    "    spamwriter = csv.writer(csvfile, delimiter=',',\n",
    "                            quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for row in csv_rows:\n",
    "        spamwriter.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
